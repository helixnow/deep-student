pub mod adapters;
mod builtin_vendors;
mod exam_engine;
mod model2_pipeline;
pub(crate) mod parser;
mod rag_extension;

use crate::crypto::{CryptoService, EncryptedData};
use crate::database::Database;
use crate::file_manager::FileManager;
use crate::models::{
    AppError, ChatMessage, ExamCardBBox, ModelAssignments,
};
use crate::providers::{ProviderAdapter, ProviderError};
use crate::vendors::load_builtin_api_configs;
use base64::{engine::general_purpose, Engine as _};
use futures_util::StreamExt;
use log::{debug, error, info, warn};
use reqwest::{header::HeaderMap, Client, ClientBuilder};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::collections::HashMap;
use std::collections::HashSet;
use std::sync::Arc;
use tauri::{Emitter, Listener, Window};
use tokio::sync::watch;
use tokio::sync::Mutex as TokioMutex;
// use chrono::Utc;
use regex::Regex;
use std::sync::LazyLock;
use tokio::sync::RwLock;
use tokio::time::{Duration, Instant};
use uuid::Uuid;

/// å¢é‡ JSON æ•°ç»„è§£æå™¨ - ç”¨äºæµå¼è§£æ LLM è¾“å‡ºçš„ JSON æ•°ç»„
/// å½“æ£€æµ‹åˆ°å®Œæ•´çš„ JSON å¯¹è±¡æ—¶ç«‹å³è¿”å›ï¼Œæ— éœ€ç­‰å¾…æ•´ä¸ªæ•°ç»„å®Œæˆ
pub(crate) struct IncrementalJsonArrayParser {
    buffer: String,
    in_array: bool,
    brace_depth: i32,
    in_string: bool,
    escape_next: bool,
}

#[cfg(test)]
mod tests {
    use super::*;

    fn profile(id: &str, label: &str, model: &str, supports_tools: bool, is_builtin: bool) -> ModelProfile {
        ModelProfile {
            id: id.to_string(),
            vendor_id: "builtin-deepseek".to_string(),
            label: label.to_string(),
            model: model.to_string(),
            supports_tools,
            is_builtin,
            ..ModelProfile::default()
        }
    }

    #[test]
    fn merge_builtin_profile_user_aware_preserves_user_modified_fields() {
        let mut profiles = vec![profile(
            "builtin-deepseek-reasoner",
            "My Custom Label",
            "deepseek-reasoner-custom",
            false,
            false,
        )];
        let builtin = profile(
            "builtin-deepseek-reasoner",
            "DeepSeek Reasoner (æ·±åº¦æ¨ç†)",
            "deepseek-reasoner",
            true,
            true,
        );
        let previous_builtin = profile(
            "builtin-deepseek-reasoner",
            "DeepSeek Reasoner (æ—§æ ‡ç­¾)",
            "deepseek-reasoner",
            true,
            true,
        );

        LLMManager::merge_builtin_profile_user_aware(
            &mut profiles,
            builtin,
            Some(&previous_builtin),
        );

        assert_eq!(profiles.len(), 1);
        let merged = &profiles[0];
        assert_eq!(merged.label, "My Custom Label");
        assert_eq!(merged.model, "deepseek-reasoner-custom");
        assert!(!merged.supports_tools);
        assert!(merged.is_builtin);
    }

    #[test]
    fn merge_builtin_profile_user_aware_updates_untouched_fields_from_builtin() {
        let mut profiles = vec![profile(
            "builtin-deepseek-chat",
            "DeepSeek Chat (æ—§æ ‡ç­¾)",
            "deepseek-chat",
            true,
            false,
        )];
        let mut builtin = profile(
            "builtin-deepseek-chat",
            "DeepSeek Chat (æ–°æ ‡ç­¾)",
            "deepseek-chat",
            true,
            true,
        );
        builtin.temperature = 0.2;

        let mut previous_builtin = profile(
            "builtin-deepseek-chat",
            "DeepSeek Chat (æ—§æ ‡ç­¾)",
            "deepseek-chat",
            true,
            true,
        );
        previous_builtin.temperature = 0.7;
        profiles[0].temperature = 0.7;

        LLMManager::merge_builtin_profile_user_aware(
            &mut profiles,
            builtin,
            Some(&previous_builtin),
        );

        assert_eq!(profiles.len(), 1);
        let merged = &profiles[0];
        assert_eq!(merged.label, "DeepSeek Chat (æ–°æ ‡ç­¾)");
        assert!((merged.temperature - 0.2).abs() < f32::EPSILON);
        assert!(merged.is_builtin);
    }

    #[test]
    fn merge_builtin_profile_user_aware_adds_missing_builtin_profile() {
        let mut profiles = vec![];
        let builtin = profile(
            "builtin-deepseek-chat",
            "DeepSeek Chat (å¯¹è¯)",
            "deepseek-chat",
            true,
            true,
        );

        LLMManager::merge_builtin_profile_user_aware(&mut profiles, builtin, None);

        assert_eq!(profiles.len(), 1);
        assert_eq!(profiles[0].id, "builtin-deepseek-chat");
        assert!(profiles[0].is_builtin);
    }

    #[test]
    fn merge_builtin_profile_user_aware_without_snapshot_syncs_capability_fields() {
        let mut profiles = vec![profile(
            "builtin-deepseek-chat",
            "User Local Label",
            "deepseek-chat-custom",
            false,
            false,
        )];
        let builtin = profile(
            "builtin-deepseek-chat",
            "DeepSeek Chat (å®˜æ–¹)",
            "deepseek-chat",
            true,
            true,
        );

        LLMManager::merge_builtin_profile_user_aware(&mut profiles, builtin, None);

        let merged = &profiles[0];
        // ç”¨æˆ·åå¥½å­—æ®µä¿æŒä¸å˜
        assert_eq!(merged.label, "User Local Label");
        assert_eq!(merged.model, "deepseek-chat-custom");
        // èƒ½åŠ›å­—æ®µä»å†…ç½®å®šä¹‰åŒæ­¥
        assert!(merged.supports_tools);
        assert!(merged.is_builtin);
    }
}

impl IncrementalJsonArrayParser {
    pub(crate) fn new() -> Self {
        Self {
            buffer: String::new(),
            in_array: false,
            brace_depth: 0,
            in_string: false,
            escape_next: false,
        }
    }

    /// è¾“å…¥æ–°çš„æ–‡æœ¬å—ï¼Œè¿”å›è§£æå‡ºçš„å®Œæ•´ JSON å¯¹è±¡åˆ—è¡¨
    pub(crate) fn feed(&mut self, chunk: &str) -> Option<Vec<Value>> {
        let mut results = Vec::new();

        for ch in chunk.chars() {
            // å¤„ç†è½¬ä¹‰å­—ç¬¦
            if self.escape_next {
                self.escape_next = false;
                if self.brace_depth > 0 {
                    self.buffer.push(ch);
                }
                continue;
            }

            if ch == '\\' && self.in_string {
                self.escape_next = true;
                if self.brace_depth > 0 {
                    self.buffer.push(ch);
                }
                continue;
            }

            // å¤„ç†å­—ç¬¦ä¸²è¾¹ç•Œ
            if ch == '"' && !self.escape_next {
                self.in_string = !self.in_string;
                if self.brace_depth > 0 {
                    self.buffer.push(ch);
                }
                continue;
            }

            // åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œç›´æ¥æ·»åŠ å­—ç¬¦
            if self.in_string {
                if self.brace_depth > 0 {
                    self.buffer.push(ch);
                }
                continue;
            }

            // æ£€æµ‹æ•°ç»„å¼€å§‹
            if ch == '[' && !self.in_array && self.brace_depth == 0 {
                self.in_array = true;
                continue;
            }

            // æ£€æµ‹æ•°ç»„ç»“æŸ
            if ch == ']' && self.in_array && self.brace_depth == 0 {
                self.in_array = false;
                continue;
            }

            // æ£€æµ‹å¯¹è±¡å¼€å§‹
            if ch == '{' {
                if self.brace_depth == 0 {
                    self.buffer.clear();
                }
                self.brace_depth += 1;
                self.buffer.push(ch);
                continue;
            }

            // æ£€æµ‹å¯¹è±¡ç»“æŸ
            if ch == '}' {
                self.brace_depth -= 1;
                self.buffer.push(ch);

                // å®Œæˆä¸€ä¸ªé¡¶å±‚å¯¹è±¡
                if self.brace_depth == 0 && !self.buffer.is_empty() {
                    if let Ok(obj) = serde_json::from_str::<Value>(&self.buffer) {
                        results.push(obj);
                    }
                    self.buffer.clear();
                }
                continue;
            }

            // å…¶ä»–å­—ç¬¦
            if self.brace_depth > 0 {
                self.buffer.push(ch);
            }
        }

        if results.is_empty() {
            None
        } else {
            Some(results)
        }
    }

    /// å¤„ç†å‰©ä½™ç¼“å†²åŒºå†…å®¹
    pub(crate) fn finalize(&mut self) -> Option<Vec<Value>> {
        if self.buffer.trim().is_empty() {
            return None;
        }

        // å°è¯•è§£æå‰©ä½™å†…å®¹
        if let Ok(obj) = serde_json::from_str::<Value>(&self.buffer) {
            self.buffer.clear();
            return Some(vec![obj]);
        }

        None
    }
}

type Result<T> = std::result::Result<T, AppError>;

const EXAM_SEGMENT_MAX_IMAGE_BYTES: usize = 1_500_000;
const EXAM_SEGMENT_MAX_DIMENSION: u32 = 1_600;
const EXAM_SEGMENT_MAX_PAGES: usize = 36;
const STREAM_MAX_CTX_TOKENS: usize = 200_000;
const USER_PREFERENCES_SETTING_KEY: &str = "chat.user_preferences_profile";
const USER_PREFERENCE_FIELD_MAX_LEN: usize = 800;
const BUILTIN_MODEL_PROFILES_SNAPSHOT_KEY: &str = "builtin_model_profiles_snapshot";

static CONTROL_CHARS_REGEX: LazyLock<Regex> =
    LazyLock::new(|| Regex::new(r"[\u{0000}-\u{001F}\u{007F}]").unwrap());

#[derive(Debug, Clone, Deserialize)]
#[serde(default)]
struct StoredUserPreferenceProfile {
    enabled: bool,
    background: String,
    goals: String,
    communication: String,
    notes: String,
}

impl Default for StoredUserPreferenceProfile {
    fn default() -> Self {
        Self {
            enabled: false,
            background: String::new(),
            goals: String::new(),
            communication: String::new(),
            notes: String::new(),
        }
    }
}

fn sanitize_user_preference_field(value: &str) -> String {
    if value.is_empty() {
        return String::new();
    }
    let cleaned = CONTROL_CHARS_REGEX.replace_all(value, "");
    let trimmed = cleaned.trim();
    if trimmed.is_empty() {
        return String::new();
    }
    let mut count = 0usize;
    let mut result = String::new();
    for ch in trimmed.chars() {
        if count >= USER_PREFERENCE_FIELD_MAX_LEN {
            break;
        }
        result.push(ch);
        count += 1;
    }
    result
}

fn build_user_preference_prompt_from_profile(
    profile: &StoredUserPreferenceProfile,
) -> Option<String> {
    if !profile.enabled {
        return None;
    }

    let background = sanitize_user_preference_field(&profile.background);
    let goals = sanitize_user_preference_field(&profile.goals);
    let communication = sanitize_user_preference_field(&profile.communication);
    let notes = sanitize_user_preference_field(&profile.notes);

    let mut lines: Vec<String> = Vec::new();
    if !background.is_empty() {
        lines.push(format!("- å­¦ä¹ èƒŒæ™¯ / Background: {}", background));
    }
    if !goals.is_empty() {
        lines.push(format!("- å­¦ä¹ ç›®æ ‡ / Goals: {}", goals));
    }
    if !communication.is_empty() {
        lines.push(format!(
            "- æ²Ÿé€šåå¥½ / Communication Style: {}",
            communication
        ));
    }
    if !notes.is_empty() {
        lines.push(format!("- è¡¥å……è¯´æ˜ / Additional Notes: {}", notes));
    }

    if lines.is_empty() {
        return None;
    }

    Some(format!(
        "### ç”¨æˆ·åå¥½ï¼ˆUser Preferencesï¼‰\n{}",
        lines.join("\n")
    ))
}

/// å‰ç«¯ MCP å·¥å…·ï¼ˆé€šè¿‡æ¡¥æ¥ä»å‰ç«¯SDKè·å–ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
struct FrontendMcpTool {
    name: String,
    #[serde(default)]
    description: Option<String>,
    #[serde(default)]
    input_schema: Value,
}

/// MCP å·¥å…·ç¼“å­˜ï¼ˆå‰ç«¯æ¥æºï¼‰
#[derive(Debug, Clone)]
struct McpToolCache {
    tools: Vec<FrontendMcpTool>,
    cached_at: Instant,
    ttl: Duration,
}

impl McpToolCache {
    fn new(tools: Vec<FrontendMcpTool>, ttl: Duration) -> Self {
        Self {
            tools,
            cached_at: Instant::now(),
            ttl,
        }
    }
    fn is_expired(&self) -> bool {
        self.cached_at.elapsed() > self.ttl
    }
}

/// OCR æ¨¡å‹é…ç½®ï¼ˆç”¨äºå¤šå¼•æ“æ”¯æŒï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct OcrModelConfig {
    /// æ¨¡å‹é…ç½® IDï¼ˆå¯¹åº” ApiConfig.idï¼‰
    pub config_id: String,
    /// æ¨¡å‹åç§°ï¼ˆå¦‚ deepseek-ai/DeepSeek-OCRï¼‰
    pub model: String,
    /// å¼•æ“ç±»å‹ï¼ˆdeepseek_ocr, paddle_ocr_vl, generic_vlmï¼‰
    pub engine_type: String,
    /// æ˜¾ç¤ºåç§°
    pub name: String,
    /// æ˜¯å¦å…è´¹
    #[serde(default)]
    pub is_free: bool,
    /// æ˜¯å¦å¯ç”¨ï¼ˆé»˜è®¤ trueï¼Œå‘åå…¼å®¹æ—§æ•°æ®ï¼‰
    #[serde(default = "default_true")]
    pub enabled: bool,
    /// ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°è¶Šä¼˜å…ˆï¼Œé»˜è®¤ 0ï¼‰
    #[serde(default)]
    pub priority: u32,
}

fn default_true() -> bool {
    true
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ApiConfig {
    pub id: String,
    pub name: String,
    #[serde(default)]
    pub vendor_id: Option<String>,
    #[serde(default)]
    pub vendor_name: Option<String>,
    #[serde(default)]
    pub provider_type: Option<String>,
    pub api_key: String,
    pub base_url: String,
    pub model: String,
    pub is_multimodal: bool,
    pub is_reasoning: bool,
    pub is_embedding: bool,
    pub is_reranker: bool,
    pub enabled: bool,
    #[serde(default = "default_model_adapter")]
    pub model_adapter: String, // æ–°å¢ï¼šæ¨¡å‹é€‚é…å™¨ç±»å‹
    #[serde(default = "default_max_output_tokens")]
    pub max_output_tokens: u32, // æ–°å¢ï¼šæœ€å¤§è¾“å‡ºTokenæ•°
    #[serde(default = "default_temperature")]
    pub temperature: f32, // æ–°å¢ï¼šæ¸©åº¦å‚æ•°
    #[serde(default, alias = "supports_tools")]
    pub supports_tools: bool, // æ–°å¢ï¼šæ˜¯å¦æ”¯æŒå·¥å…·/å‡½æ•°è°ƒç”¨
    #[serde(default = "default_gemini_api_version")]
    pub gemini_api_version: String, // æ–°å¢ï¼šGemini APIç‰ˆæœ¬ï¼ˆv1æˆ–v1betaï¼‰
    #[serde(default)]
    pub is_builtin: bool,
    #[serde(default)]
    pub is_read_only: bool,
    #[serde(default)]
    pub reasoning_effort: Option<String>,
    #[serde(default)]
    pub thinking_enabled: bool,
    #[serde(default)]
    pub thinking_budget: Option<i32>,
    #[serde(default)]
    pub include_thoughts: bool,
    #[serde(default)]
    pub min_p: Option<f32>,
    #[serde(default)]
    pub top_k: Option<u32>,
    #[serde(default)]
    pub enable_thinking: Option<bool>,
    #[serde(default)]
    pub supports_reasoning: bool,
    #[serde(default)]
    pub headers: Option<HashMap<String, String>>,
    /// Top-P æ ¸é‡‡æ ·å‚æ•°ï¼ˆè¿è¡Œæ—¶è¦†ç›–ç”¨ï¼‰
    #[serde(default)]
    pub top_p_override: Option<f32>,
    /// é¢‘ç‡æƒ©ç½šï¼ˆè¿è¡Œæ—¶è¦†ç›–ç”¨ï¼‰
    #[serde(default)]
    pub frequency_penalty_override: Option<f32>,
    /// å­˜åœ¨æƒ©ç½šï¼ˆè¿è¡Œæ—¶è¦†ç›–ç”¨ï¼‰
    #[serde(default)]
    pub presence_penalty_override: Option<f32>,
    /// é‡å¤æƒ©ç½šï¼ˆQwen/è±†åŒ…ç­‰æ¨¡å‹ä½¿ç”¨ï¼‰
    /// Qwen: >1.0 è¡¨ç¤ºæƒ©ç½šé‡å¤ï¼Œ1.0 è¡¨ç¤ºä¸æƒ©ç½š
    /// è±†åŒ…: >0 è¡¨ç¤ºæƒ©ç½šå¼ºåº¦
    #[serde(default)]
    pub repetition_penalty: Option<f32>,
    /// MiniMax reasoning_split å‚æ•°
    /// true: æ€ç»´å†…å®¹åˆ†ç¦»åˆ° reasoning_details å­—æ®µï¼ˆæ¨èï¼‰
    /// false: æ€ç»´å†…å®¹åµŒå…¥åœ¨ content å­—æ®µä¸­ç”¨ <think> æ ‡ç­¾åŒ…è£¹
    #[serde(default)]
    pub reasoning_split: Option<bool>,
    /// Claude 4.5 Opus effort å‚æ•° (high/medium/low)
    #[serde(default)]
    pub effort: Option<String>,
    /// OpenAI GPT-5.2 verbosity å‚æ•° (low/medium/high)
    #[serde(default)]
    pub verbosity: Option<String>,
    /// æ˜¯å¦æ”¶è—ï¼ˆæ”¶è—çš„æ¨¡å‹åœ¨åˆ—è¡¨ä¸­ä¼˜å…ˆæ˜¾ç¤ºï¼‰
    #[serde(default)]
    pub is_favorite: bool,
    /// ä¾›åº”å•†çº§åˆ«çš„ max_tokens é™åˆ¶ï¼ˆAPI æœ€å¤§å…è®¸å€¼ï¼‰
    #[serde(default)]
    pub max_tokens_limit: Option<u32>,
}

impl Default for ApiConfig {
    fn default() -> Self {
        Self {
            id: String::new(),
            name: String::new(),
            vendor_id: None,
            vendor_name: None,
            provider_type: None,
            api_key: String::new(),
            base_url: String::new(),
            model: String::new(),
            is_multimodal: false,
            is_reasoning: false,
            is_embedding: false,
            is_reranker: false,
            enabled: false,
            model_adapter: default_model_adapter(),
            max_output_tokens: default_max_output_tokens(),
            temperature: default_temperature(),
            supports_tools: false,
            gemini_api_version: default_gemini_api_version(),
            is_builtin: false,
            is_read_only: false,
            reasoning_effort: None,
            thinking_enabled: false,
            thinking_budget: None,
            include_thoughts: false,
            min_p: None,
            top_k: None,
            enable_thinking: None,
            supports_reasoning: false,
            headers: None,
            top_p_override: None,
            frequency_penalty_override: None,
            presence_penalty_override: None,
            repetition_penalty: None,
            reasoning_split: None,
            effort: None,
            verbosity: None,
            is_favorite: false,
            max_tokens_limit: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct VendorConfig {
    pub id: String,
    pub name: String,
    pub provider_type: String,
    pub base_url: String,
    pub api_key: String,
    #[serde(default)]
    pub headers: HashMap<String, String>,
    #[serde(default)]
    pub rate_limit_per_minute: Option<u32>,
    #[serde(default)]
    pub default_timeout_ms: Option<u64>,
    #[serde(default)]
    pub notes: Option<String>,
    #[serde(default)]
    pub is_builtin: bool,
    #[serde(default)]
    pub is_read_only: bool,
    #[serde(default)]
    pub sort_order: Option<i32>,
    /// ä¾›åº”å•†çº§åˆ«çš„ max_tokens é™åˆ¶ï¼ˆAPI æœ€å¤§å…è®¸å€¼ï¼‰
    #[serde(default)]
    pub max_tokens_limit: Option<u32>,
    /// ä¾›åº”å•†å®˜ç½‘é“¾æ¥
    #[serde(default)]
    pub website_url: Option<String>,
}

impl Default for VendorConfig {
    fn default() -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            name: "New Vendor".to_string(),
            provider_type: "openai".to_string(),
            base_url: String::new(),
            api_key: String::new(),
            headers: HashMap::new(),
            rate_limit_per_minute: None,
            default_timeout_ms: None,
            notes: None,
            is_builtin: false,
            is_read_only: false,
            sort_order: None,
            max_tokens_limit: None,
            website_url: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct ModelProfile {
    pub id: String,
    pub vendor_id: String,
    pub label: String,
    pub model: String,
    #[serde(default = "default_model_adapter")]
    pub model_adapter: String,
    #[serde(default)]
    pub is_multimodal: bool,
    #[serde(default)]
    pub is_reasoning: bool,
    #[serde(default)]
    pub is_embedding: bool,
    #[serde(default)]
    pub is_reranker: bool,
    #[serde(default)]
    pub supports_tools: bool,
    #[serde(default)]
    pub supports_reasoning: bool,
    #[serde(default = "default_profile_status")]
    pub status: String,
    #[serde(default = "default_profile_enabled")]
    pub enabled: bool,
    #[serde(default = "default_max_output_tokens")]
    pub max_output_tokens: u32,
    #[serde(default = "default_temperature")]
    pub temperature: f32,
    #[serde(default)]
    pub reasoning_effort: Option<String>,
    #[serde(default)]
    pub thinking_enabled: bool,
    #[serde(default)]
    pub thinking_budget: Option<i32>,
    #[serde(default)]
    pub include_thoughts: bool,
    #[serde(default)]
    pub enable_thinking: Option<bool>,
    #[serde(default)]
    pub min_p: Option<f32>,
    #[serde(default)]
    pub top_k: Option<u32>,
    #[serde(default)]
    pub gemini_api_version: Option<String>,
    #[serde(default)]
    pub is_builtin: bool,
    /// é‡å¤æƒ©ç½šï¼ˆQwen/è±†åŒ…ç­‰æ¨¡å‹ä½¿ç”¨ï¼‰
    #[serde(default)]
    pub repetition_penalty: Option<f32>,
    /// MiniMax reasoning_split å‚æ•°
    #[serde(default)]
    pub reasoning_split: Option<bool>,
    #[serde(default)]
    pub effort: Option<String>,
    #[serde(default)]
    pub verbosity: Option<String>,
    /// æ˜¯å¦æ”¶è—ï¼ˆæ”¶è—çš„æ¨¡å‹åœ¨åˆ—è¡¨ä¸­ä¼˜å…ˆæ˜¾ç¤ºï¼‰
    #[serde(default)]
    pub is_favorite: bool,
    /// æ¨¡å‹çº§åˆ«çš„ max_tokens é™åˆ¶ï¼ˆä¼˜å…ˆäºä¾›åº”å•†çº§åˆ«ï¼‰
    #[serde(default)]
    pub max_tokens_limit: Option<u32>,
}

impl Default for ModelProfile {
    fn default() -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            vendor_id: String::new(),
            label: "New Model".to_string(),
            model: String::new(),
            model_adapter: default_model_adapter(),
            is_multimodal: false,
            is_reasoning: false,
            is_embedding: false,
            is_reranker: false,
            supports_tools: false,
            supports_reasoning: false,
            status: default_profile_status(),
            enabled: default_profile_enabled(),
            max_output_tokens: default_max_output_tokens(),
            temperature: default_temperature(),
            reasoning_effort: None,
            thinking_enabled: false,
            thinking_budget: None,
            include_thoughts: false,
            enable_thinking: None,
            min_p: None,
            top_k: None,
            gemini_api_version: None,
            is_builtin: false,
            repetition_penalty: None,
            reasoning_split: None,
            effort: None,
            verbosity: None,
            is_favorite: false,
            max_tokens_limit: None,
        }
    }
}

#[derive(Debug, Clone)]
pub struct ResolvedModelConfig {
    pub vendor: VendorConfig,
    pub profile: ModelProfile,
    pub runtime: ApiConfig,
}

// é»˜è®¤å€¼å‡½æ•°
fn default_model_adapter() -> String {
    "general".to_string()
}

fn default_max_output_tokens() -> u32 {
    8192
}

fn default_temperature() -> f32 {
    0.7
}

fn default_gemini_api_version() -> String {
    "v1".to_string()
}

fn default_profile_status() -> String {
    "enabled".to_string()
}

fn default_profile_enabled() -> bool {
    true
}

#[inline]
pub(crate) fn effective_max_tokens(max_output_tokens: u32, max_tokens_limit: Option<u32>) -> u32 {
    match max_tokens_limit {
        Some(limit) => max_output_tokens.min(limit),
        None => max_output_tokens,
    }
}

#[derive(Debug, Clone)]
pub struct ExamSegmentationCard {
    pub question_label: String,
    pub bbox: ExamCardBBox,
    pub ocr_text: Option<String>,
    pub tags: Vec<String>,
    pub extra_metadata: Option<Value>,
    pub card_id: String,
}

#[derive(Debug, Clone)]
pub struct ExamSegmentationPage {
    pub page_index: usize,
    pub cards: Vec<ExamSegmentationCard>,
}

#[derive(Debug, Clone)]
pub struct ExamSegmentationOutput {
    pub pages: Vec<ExamSegmentationPage>,
    pub raw: Option<Value>,
}

pub struct LLMManager {
    client: Client,
    db: Arc<Database>,
    file_manager: Arc<FileManager>,
    crypto_service: CryptoService,
    cancel_registry: Arc<TokioMutex<HashSet<String>>>,
    cancel_channels: Arc<TokioMutex<std::collections::HashMap<String, watch::Sender<bool>>>>,
    mcp_tool_cache: Arc<RwLock<Option<McpToolCache>>>,
    hooks_registry:
        Arc<TokioMutex<std::collections::HashMap<String, std::sync::Arc<dyn LLMStreamHooks>>>>,
}

#[derive(Debug, Clone)]
pub(crate) struct ImagePayload {
    pub mime: String,
    pub base64: String,
}

/// ğŸ”§ P1ä¿®å¤ï¼šåˆå¹¶åçš„æ¶ˆæ¯ç±»å‹
/// ç”¨äºåœ¨æ¶ˆæ¯åºåˆ—åŒ–æ—¶åˆå¹¶è¿ç»­çš„å·¥å…·è°ƒç”¨
enum MergedChatMessage {
    /// æ™®é€šæ¶ˆæ¯ï¼ˆç›´æ¥ä¼ é€’ï¼‰
    Regular(ChatMessage),
    /// åˆå¹¶çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆå¤šä¸ª tool_callsï¼‰
    /// ğŸ”§ Anthropic æœ€ä½³å®è·µï¼šå¿…é¡»ä¿ç•™ thinking_content
    /// "When using thinking enabled + tool calling, you must include thinking_blocks
    /// from the previous assistant response when sending tool results back."
    MergedToolCalls {
        tool_calls: Vec<crate::models::ToolCall>,
        content: String,
        /// ğŸ”§ ä¿ç•™ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨å¯¹åº”çš„æ€ç»´é“¾ï¼ˆAnthropic è¦æ±‚ï¼‰
        thinking_content: Option<String>,
        /// ğŸ”§ Gemini 3 æ€ç»´ç­¾åï¼šå·¥å…·è°ƒç”¨åœºæ™¯ä¸‹å¿…é¡»åœ¨åç»­è¯·æ±‚ä¸­å›ä¼ 
        thought_signature: Option<String>,
    },
}

// Optional streaming hooks for unified pipeline to observe and persist events
pub trait LLMStreamHooks: Send + Sync {
    fn on_content_chunk(&self, _text: &str) {}
    fn on_reasoning_chunk(&self, _text: &str) {}
    /// Gemini 3 æ€ç»´ç­¾åå›è°ƒï¼ˆå·¥å…·è°ƒç”¨å¿…éœ€ï¼‰
    /// åœ¨å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹ï¼Œéœ€è¦ç¼“å­˜æ­¤ç­¾åå¹¶åœ¨åç»­è¯·æ±‚ä¸­å›ä¼ 
    fn on_thought_signature(&self, _signature: &str) {}
    /// ğŸ†• 2026-01-15: å·¥å…·è°ƒç”¨å‚æ•°å¼€å§‹ç´¯ç§¯æ—¶é€šçŸ¥å‰ç«¯
    /// åœ¨ LLM å¼€å§‹ç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°æ—¶ç«‹å³è°ƒç”¨ï¼Œè®©å‰ç«¯æ˜¾ç¤º"æ­£åœ¨å‡†å¤‡å·¥å…·è°ƒç”¨"
    /// - tool_call_id: å·¥å…·è°ƒç”¨ ID
    /// - tool_name: å·¥å…·åç§°
    fn on_tool_call_start(&self, _tool_call_id: &str, _tool_name: &str) {}
    /// å·¥å…·è°ƒç”¨å‚æ•°æµå¼ç‰‡æ®µå›è°ƒ
    /// åœ¨ LLM é€ token ç”Ÿæˆå·¥å…·è°ƒç”¨ arguments æ—¶è°ƒç”¨ï¼Œç”¨äºå‰ç«¯å®æ—¶é¢„è§ˆ
    fn on_tool_call_args_delta(&self, _tool_call_id: &str, _delta: &str) {}
    fn on_tool_call(&self, _msg: &ChatMessage) {}
    fn on_tool_result(&self, _msg: &ChatMessage) {}
    fn on_usage(&self, _usage: &serde_json::Value) {}
    fn on_complete(&self, _final_text: &str, _reasoning: Option<&str>) {}
}

impl LLMManager {
    fn merge_builtin_profile_user_aware(
        profiles: &mut Vec<ModelProfile>,
        builtin_profile: ModelProfile,
        previous_builtin_profile: Option<&ModelProfile>,
    ) {
        if let Some(existing) = profiles.iter_mut().find(|p| p.id == builtin_profile.id) {
            // æ— è®ºå¦‚ä½•éƒ½ä¿®å¤å†…ç½®æ ‡è®°ï¼Œé¿å…æ—§æ•°æ®å°†å†…ç½®æ¨¡å‹é”™è¯¯æ ‡è®°ä¸ºéå†…ç½®ã€‚
            existing.is_builtin = true;

            // é¦–æ¬¡æ— åŸºçº¿å¿«ç…§æ—¶ï¼šèƒ½åŠ›å­—æ®µä»å†…ç½®å®šä¹‰åŒæ­¥ï¼ˆç”¨æˆ·æå°‘æ‰‹åŠ¨ä¿®æ”¹ï¼‰ï¼Œ
            // ç”¨æˆ·åå¥½å­—æ®µï¼ˆæ ‡ç­¾ã€æ¨¡å‹IDã€æ¸©åº¦ç­‰ï¼‰ä¿æŒä¸å˜ã€‚
            let Some(previous_builtin) = previous_builtin_profile else {
                existing.is_multimodal = builtin_profile.is_multimodal;
                existing.is_reasoning = builtin_profile.is_reasoning;
                existing.is_embedding = builtin_profile.is_embedding;
                existing.is_reranker = builtin_profile.is_reranker;
                existing.supports_tools = builtin_profile.supports_tools;
                existing.supports_reasoning = builtin_profile.supports_reasoning;
                return;
            };

            macro_rules! update_if_untouched {
                ($field:ident) => {
                    if existing.$field == previous_builtin.$field {
                        existing.$field = builtin_profile.$field.clone();
                    }
                };
            }

            update_if_untouched!(vendor_id);
            update_if_untouched!(label);
            update_if_untouched!(model);
            update_if_untouched!(model_adapter);
            update_if_untouched!(is_multimodal);
            update_if_untouched!(is_reasoning);
            update_if_untouched!(is_embedding);
            update_if_untouched!(is_reranker);
            update_if_untouched!(supports_tools);
            update_if_untouched!(supports_reasoning);
            update_if_untouched!(status);
            update_if_untouched!(enabled);
            update_if_untouched!(max_output_tokens);
            update_if_untouched!(temperature);
            update_if_untouched!(reasoning_effort);
            update_if_untouched!(thinking_enabled);
            update_if_untouched!(thinking_budget);
            update_if_untouched!(include_thoughts);
            update_if_untouched!(enable_thinking);
            update_if_untouched!(min_p);
            update_if_untouched!(top_k);
            update_if_untouched!(gemini_api_version);
            update_if_untouched!(repetition_penalty);
            update_if_untouched!(reasoning_split);
            update_if_untouched!(effort);
            update_if_untouched!(verbosity);
            update_if_untouched!(is_favorite);
            update_if_untouched!(max_tokens_limit);
            return;
        }
        profiles.push(builtin_profile);
    }

    fn read_builtin_profile_snapshot_map(&self) -> HashMap<String, ModelProfile> {
        let raw = match self.db.get_setting(BUILTIN_MODEL_PROFILES_SNAPSHOT_KEY) {
            Ok(Some(raw)) => raw,
            _ => return HashMap::new(),
        };

        let parsed: Vec<ModelProfile> = match serde_json::from_str(&raw) {
            Ok(parsed) => parsed,
            Err(err) => {
                warn!("[VendorModel] è§£æå†…ç½®æ¨¡å‹å¿«ç…§å¤±è´¥ï¼Œå›é€€ä¸ºç©ºå¿«ç…§: {}", err);
                return HashMap::new();
            }
        };

        parsed
            .into_iter()
            .map(|profile| (profile.id.clone(), profile))
            .collect()
    }

    fn save_builtin_profile_snapshot(&self, builtin_profiles: &[ModelProfile]) -> Result<()> {
        let json = serde_json::to_string(builtin_profiles)
            .map_err(|e| AppError::configuration(format!("åºåˆ—åŒ–å†…ç½®æ¨¡å‹å¿«ç…§å¤±è´¥: {}", e)))?;
        self.db
            .save_setting(BUILTIN_MODEL_PROFILES_SNAPSHOT_KEY, &json)
            .map_err(|e| AppError::database(format!("ä¿å­˜å†…ç½®æ¨¡å‹å¿«ç…§å¤±è´¥: {}", e)))
    }

    pub fn new(db: Arc<Database>, file_manager: Arc<FileManager>) -> Result<Self> {
        let client = Self::create_http_client_with_fallback();

        let app_data_dir_path = file_manager.get_app_data_dir();
        let crypto_service = CryptoService::new(&app_data_dir_path.to_path_buf())
            .map_err(|e| AppError::configuration(format!("åŠ å¯†æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")))?;

        Ok(Self {
            client,
            db,
            file_manager,
            crypto_service,
            cancel_registry: Arc::new(TokioMutex::new(HashSet::new())),
            cancel_channels: Arc::new(TokioMutex::new(std::collections::HashMap::new())),
            mcp_tool_cache: Arc::new(RwLock::new(None)),
            hooks_registry: Arc::new(TokioMutex::new(std::collections::HashMap::new())),
        })
    }

    // å¯¹å¤–æš´éœ² HTTP å®¢æˆ·ç«¯ï¼Œä¾¿äºç‹¬ç«‹ç®¡çº¿é‡ç”¨ç»Ÿä¸€é…ç½®çš„å®¢æˆ·ç«¯
    pub fn get_http_client(&self) -> Client {
        self.client.clone()
    }

    // è®¢é˜…æŒ‡å®šæµäº‹ä»¶çš„å–æ¶ˆé€šé“ï¼ˆç”¨äºç‹¬ç«‹æµå¼å®ç°ï¼‰
    pub async fn subscribe_cancel_stream(&self, stream_event: &str) -> watch::Receiver<bool> {
        self.register_cancel_channel(stream_event).await
    }

    // æ¸…ç†æŒ‡å®šæµäº‹ä»¶çš„å–æ¶ˆé€šé“ï¼ˆç”¨äºç‹¬ç«‹æµå¼å®ç°ï¼‰
    pub async fn clear_cancel_stream(&self, stream_event: &str) {
        self.clear_cancel_channel(stream_event).await;
    }

    // è‹¥å–æ¶ˆåœ¨é€šé“æ³¨å†Œå‰å·²å‘ç”Ÿï¼Œæä¾›ä¸€æ¬¡æ€§æ¶ˆè´¹æ¥å£
    pub async fn consume_pending_cancel(&self, stream_event: &str) -> bool {
        self.take_cancellation_if_any(stream_event).await
    }

    fn log_request_body(&self, tag: &str, body: &serde_json::Value) {
        match serde_json::to_string_pretty(body) {
            Ok(pretty) => debug!("[{}] è¯·æ±‚ä½“å¦‚ä¸‹:\n{}", tag, pretty),
            Err(e) => warn!("[{}] è¯·æ±‚ä½“åºåˆ—åŒ–å¤±è´¥: {}", tag, e),
        }
    }

    pub fn user_preference_prompt(&self) -> Option<String> {
        let stored = match self.db.get_setting(USER_PREFERENCES_SETTING_KEY) {
            Ok(value) => value?,
            Err(err) => {
                warn!("[UserPreferences] è¯»å–å¤±è´¥: {}", err);
                return None;
            }
        };

        let trimmed = stored.trim();
        if trimmed.is_empty() {
            return None;
        }

        let mut profile = match serde_json::from_str::<StoredUserPreferenceProfile>(trimmed) {
            Ok(parsed) => parsed,
            Err(_) => StoredUserPreferenceProfile {
                enabled: true,
                notes: trimmed.to_string(),
                ..Default::default()
            },
        };

        if !trimmed.contains("\"enabled\"") {
            let has_any_content = !profile.background.trim().is_empty()
                || !profile.goals.trim().is_empty()
                || !profile.communication.trim().is_empty()
                || !profile.notes.trim().is_empty();
            if has_any_content {
                profile.enabled = true;
            }
        }

        // å…è®¸ç©ºç™½å­—æ®µï¼Œä½† enabled ä¸º false æ—¶ç›´æ¥è·³è¿‡
        if !profile.enabled {
            return None;
        }

        build_user_preference_prompt_from_profile(&profile)
    }

    fn provider_error(context: &str, err: ProviderError) -> AppError {
        AppError::llm(format!("{}: {}", context, err))
    }

    /// åº”ç”¨æ¨ç†ç›¸å…³é…ç½®åˆ°è¯·æ±‚ä½“
    ///
    /// ä½¿ç”¨å­é€‚é…å™¨ç³»ç»Ÿå¤„ç†ä¸åŒä¾›åº”å•†çš„å‚æ•°å·®å¼‚ï¼š
    /// - é€šè¿‡ `provider_type` æŸ¥æ‰¾å¯¹åº”çš„å­é€‚é…å™¨
    /// - å­é€‚é…å™¨å¤„ç†ç‰¹å®šä¾›åº”å•†çš„å‚æ•°æ ¼å¼
    /// - æœ€ååº”ç”¨é€šç”¨å‚æ•°
    ///
    /// ## å­é€‚é…å™¨æ¶æ„
    /// è¯¦è§ `adapters` æ¨¡å—æ–‡æ¡£
    fn apply_reasoning_config(body: &mut Value, config: &ApiConfig, enable_thinking: Option<bool>) {
        let Value::Object(map) = body else {
            return;
        };

        // è·å–é€‚é…å™¨ï¼šä¼˜å…ˆä½¿ç”¨ provider_typeï¼Œå›é€€åˆ° model_adapter
        // æ³¨æ„ï¼šé€‚é…å™¨ç±»å‹ç”±å‰ç«¯æ¨æ–­å¼•æ“åœ¨é…ç½®æ—¶é¢„è®¾ï¼Œåç«¯ç›´æ¥ä½¿ç”¨
        let adapter = adapters::get_adapter(config.provider_type.as_deref(), &config.model_adapter);

        // ç§»é™¤é‡‡æ ·å‚æ•°ï¼ˆå¦‚æœé€‚é…å™¨è¦æ±‚ï¼‰
        if adapter.should_remove_sampling_params(config) {
            map.remove("temperature");
            map.remove("top_p");
            map.remove("logprobs");
        }

        // åº”ç”¨æ¨ç†é…ç½®
        let early_return = adapter.apply_reasoning_config(map, config, enable_thinking);

        if early_return {
            return;
        }

        // åº”ç”¨é€šç”¨å‚æ•°
        adapter.apply_common_params(map, config);
    }

    // -------- Streaming Hooks (for unified pipeline) --------
    pub async fn register_stream_hooks(
        &self,
        stream_event: &str,
        hooks: std::sync::Arc<dyn LLMStreamHooks>,
    ) {
        let key = stream_event.to_string();
        debug!("[Hook] æ³¨å†Œ hook: key={}", key);
        self.hooks_registry.lock().await.insert(key, hooks);
        let count = self.hooks_registry.lock().await.len();
        debug!("[Hook] æ³¨å†Œå registry å¤§å°: {}", count);
    }

    pub async fn unregister_stream_hooks(&self, stream_event: &str) {
        let key = stream_event.to_string();
        debug!("[Hook] æ³¨é”€ hook: key={}", key);
        self.hooks_registry.lock().await.remove(&key);
    }

    async fn get_hook(&self, stream_event: &str) -> Option<std::sync::Arc<dyn LLMStreamHooks>> {
        let registry = self.hooks_registry.lock().await;
        // æ—¥å¿—å·²ç®€åŒ–ï¼šåªåœ¨ debug æ¨¡å¼ä¸‹è¾“å‡º
        registry.get(stream_event).cloned()
    }

    /// ğŸ”§ P1ä¿®å¤ï¼šåˆå¹¶è¿ç»­çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
    ///
    /// OpenAI åè®®æœŸæœ›ï¼šä¸€ä¸ª assistant æ¶ˆæ¯åŒ…å« tool_calls æ•°ç»„ï¼Œç„¶åè·Ÿç€å¤šä¸ª tool æ¶ˆæ¯ã€‚
    /// å½“å‰æ•°æ®æ¨¡å‹æ¯ä¸ªæ¶ˆæ¯åªæœ‰ä¸€ä¸ª tool_callï¼Œéœ€è¦åœ¨åºåˆ—åŒ–æ—¶åˆå¹¶ã€‚
    ///
    /// ğŸ”§ Anthropic æœ€ä½³å®è·µï¼šå¿…é¡»ä¿ç•™ thinking_content
    /// "When using thinking enabled + tool calling, you must include thinking_blocks
    /// from the previous assistant response when sending tool results back."
    ///
    /// è¾“å…¥ï¼š[assistant(tc1, thinking1), tool(tr1), assistant(tc2), tool(tr2), assistant(tc3, thinking2), tool(tr3)]
    /// è¾“å‡ºï¼š[MergedToolCalls([tc1, tc2], thinking1), tool(tr1), tool(tr2), MergedToolCalls([tc3], thinking2), tool(tr3)]
    ///
    /// ## ğŸ”§ å¤šè½®å·¥å…·è°ƒç”¨è¾¹ç•Œæ£€æµ‹
    /// å½“é‡åˆ°æ–°çš„ reasoning_contentï¼ˆéç©ºï¼‰æ—¶ï¼Œè¡¨ç¤ºå¼€å§‹äº†æ–°ä¸€è½®çš„å·¥å…·è°ƒç”¨ï¼Œ
    /// éœ€è¦åˆ·æ–°å½“å‰çš„ pending ç»„å¹¶å¼€å§‹æ–°ç»„ï¼Œä»¥ä¿æŒæ¯è½®å·¥å…·è°ƒç”¨çš„è¾¹ç•Œã€‚
    /// è¿™ç¡®ä¿äº†å¤šè½®å·¥å…·è°ƒç”¨çš„æ€ç»´é“¾éƒ½èƒ½è¢«æ­£ç¡®ä¿ç•™å’Œå›ä¼ ã€‚
    fn merge_consecutive_tool_calls(history: &[ChatMessage]) -> Vec<MergedChatMessage> {
        let mut result = Vec::new();
        let mut pending_tool_calls: Vec<crate::models::ToolCall> = Vec::new();
        let mut pending_tool_results: Vec<ChatMessage> = Vec::new();
        // ğŸ”§ ä¿ç•™å½“å‰è½®æ¬¡çš„æ€ç»´é“¾
        let mut current_thinking_content: Option<String> = None;
        // ğŸ”§ Gemini 3 æ€ç»´ç­¾åï¼šå·¥å…·è°ƒç”¨åœºæ™¯ä¸‹å¿…é¡»å›ä¼ 
        let mut current_thought_signature: Option<String> = None;

        for msg in history {
            if msg.role == "assistant" && msg.tool_call.is_some() {
                if let Some(tc) = &msg.tool_call {
                    // ğŸ”§ å¤šè½®è¾¹ç•Œæ£€æµ‹ï¼šå¦‚æœé‡åˆ°æ–°çš„ reasoning_contentï¼ˆéç©ºï¼‰ï¼Œ
                    // ä¸”å·²ç»æœ‰å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨ï¼Œåˆ™å…ˆåˆ·æ–°å½“å‰ç»„
                    let has_new_reasoning = msg
                        .thinking_content
                        .as_ref()
                        .map(|s| !s.is_empty())
                        .unwrap_or(false);

                    if has_new_reasoning && !pending_tool_calls.is_empty() {
                        // åˆ·æ–°å½“å‰ç»„ï¼ˆè¿™æ˜¯å‰ä¸€è½®çš„å·¥å…·è°ƒç”¨ï¼‰
                        result.push(MergedChatMessage::MergedToolCalls {
                            tool_calls: std::mem::take(&mut pending_tool_calls),
                            content: String::new(),
                            thinking_content: std::mem::take(&mut current_thinking_content),
                            thought_signature: std::mem::take(&mut current_thought_signature),
                        });
                        for tr in std::mem::take(&mut pending_tool_results) {
                            result.push(MergedChatMessage::Regular(tr));
                        }

                        debug!(
                            "[LLMManager] New reasoning round detected, flushed previous tool calls group"
                        );
                    }

                    // æ”¶é›†å·¥å…·è°ƒç”¨
                    pending_tool_calls.push(tc.clone());

                    // ä¿ç•™å½“å‰è½®æ¬¡çš„æ€ç»´é“¾ï¼ˆåªä¿ç•™ç¬¬ä¸€ä¸ªéç©ºçš„ï¼‰
                    if current_thinking_content.is_none() && has_new_reasoning {
                        current_thinking_content = msg.thinking_content.clone();
                    }
                    // ä¿ç•™å½“å‰è½®æ¬¡çš„æ€ç»´ç­¾åï¼ˆåªä¿ç•™ç¬¬ä¸€ä¸ªéç©ºçš„ï¼‰
                    if current_thought_signature.is_none() {
                        current_thought_signature = msg.thought_signature.clone();
                    }
                }
            } else if msg.role == "tool" {
                // æ”¶é›†å·¥å…·ç»“æœ
                pending_tool_results.push(msg.clone());
            } else {
                // éå·¥å…·æ¶ˆæ¯ï¼Œå…ˆåˆ·æ–°å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨
                if !pending_tool_calls.is_empty() {
                    result.push(MergedChatMessage::MergedToolCalls {
                        tool_calls: std::mem::take(&mut pending_tool_calls),
                        content: String::new(),
                        thinking_content: std::mem::take(&mut current_thinking_content),
                        thought_signature: std::mem::take(&mut current_thought_signature),
                    });
                    for tr in std::mem::take(&mut pending_tool_results) {
                        result.push(MergedChatMessage::Regular(tr));
                    }
                }
                result.push(MergedChatMessage::Regular(msg.clone()));
            }
        }

        // å¤„ç†å°¾éƒ¨çš„å·¥å…·è°ƒç”¨
        if !pending_tool_calls.is_empty() {
            result.push(MergedChatMessage::MergedToolCalls {
                tool_calls: pending_tool_calls,
                content: String::new(),
                thinking_content: current_thinking_content,
                thought_signature: current_thought_signature,
            });
            for tr in pending_tool_results {
                result.push(MergedChatMessage::Regular(tr));
            }
        }

        result
    }

    /// ğŸ”§ åˆå¹¶è¿ç»­åŒè§’è‰²çš„ç”¨æˆ·æ¶ˆæ¯ï¼ˆé˜²å¾¡æ€§æªæ–½ï¼‰
    ///
    /// éƒ¨åˆ† LLM APIï¼ˆå¦‚ Anthropic Claude åŸç”Ÿ APIã€æ–‡å¿ƒä¸€è¨€ï¼‰ä¸¥æ ¼è¦æ±‚ user/assistant äº¤æ›¿ã€‚
    /// å½“ä»¥ä¸‹åœºæ™¯å‘ç”Ÿæ—¶ï¼Œå¯èƒ½äº§ç”Ÿè¿ç»­çš„ user æ¶ˆæ¯ï¼š
    /// 1. assistant å›å¤ä¸ºç©ºï¼ˆè¢«å–æ¶ˆ/å¤±è´¥ï¼‰è¢« `load_chat_history` è·³è¿‡
    /// 2. ä¼šè¯åˆ†æ”¯åç”¨æˆ·ç»§ç»­å‘é€æ–°æ¶ˆæ¯
    /// 3. æ¶ˆæ¯ç¼–è¾‘ç­‰è¾¹ç•Œæƒ…å†µ
    ///
    /// æ­¤å‡½æ•°åœ¨ messages æ•°ç»„æ„å»ºå®Œæˆåã€å‘é€è¯·æ±‚å‰è°ƒç”¨ï¼Œ
    /// å°†è¿ç»­çš„åŒè§’è‰² user æ¶ˆæ¯ç”¨ `\n\n` åˆå¹¶ä¸ºå•æ¡æ¶ˆæ¯ã€‚
    /// å¯¹ system / assistant / tool æ¶ˆæ¯ä¸åšåˆå¹¶ï¼ˆå®ƒä»¬æœ‰å„è‡ªçš„è¯­ä¹‰ï¼‰ã€‚
    ///
    /// æ³¨æ„ï¼šä»…åˆå¹¶ content ä¸ºçº¯å­—ç¬¦ä¸²çš„ user æ¶ˆæ¯ã€‚
    /// å¯¹äº content ä¸ºæ•°ç»„ï¼ˆå¤šæ¨¡æ€ï¼‰çš„æƒ…å†µï¼Œå°†æ•°ç»„å…ƒç´ è¿½åŠ åˆ°å‰ä¸€æ¡ã€‚
    pub(crate) fn merge_consecutive_user_messages(messages: &mut Vec<serde_json::Value>) {
        if messages.len() < 2 {
            return;
        }

        let mut merged: Vec<serde_json::Value> = Vec::with_capacity(messages.len());

        for msg in messages.drain(..) {
            let is_user = msg.get("role").and_then(|r| r.as_str()) == Some("user");

            if !is_user {
                merged.push(msg);
                continue;
            }

            // æ£€æŸ¥å‰ä¸€æ¡æ˜¯å¦ä¹Ÿæ˜¯ user
            let prev_is_user = merged
                .last()
                .and_then(|m| m.get("role"))
                .and_then(|r| r.as_str())
                == Some("user");

            if !prev_is_user {
                merged.push(msg);
                continue;
            }

            // éœ€è¦åˆå¹¶ï¼šå°†å½“å‰ user æ¶ˆæ¯çš„ content è¿½åŠ åˆ°å‰ä¸€æ¡
            let prev = merged.last_mut().unwrap();
            let prev_content = prev.get("content").cloned();
            let curr_content = msg.get("content").cloned();

            match (prev_content, curr_content) {
                // ä¸¤æ¡éƒ½æ˜¯çº¯æ–‡æœ¬ â†’ ç”¨ \n\n æ‹¼æ¥
                (Some(serde_json::Value::String(ref prev_text)), Some(serde_json::Value::String(ref curr_text))) => {
                    let merged_text = format!("{}\n\n{}", prev_text, curr_text);
                    let combined_len = merged_text.len();
                    prev["content"] = serde_json::Value::String(merged_text);
                    log::warn!(
                        "[LLMManager] Merged 2 consecutive user messages (text+text, combined_len={})",
                        combined_len
                    );
                }
                // å‰ä¸€æ¡æ˜¯æ•°ç»„ï¼ˆå¤šæ¨¡æ€ï¼‰ï¼Œå½“å‰ä¹Ÿæ˜¯æ•°ç»„ â†’ è¿½åŠ å…ƒç´ 
                (Some(serde_json::Value::Array(ref _prev_arr)), Some(serde_json::Value::Array(ref curr_arr))) => {
                    let curr_len = curr_arr.len();
                    if let Some(arr) = prev.get_mut("content").and_then(|c| c.as_array_mut()) {
                        arr.extend(curr_arr.clone());
                        log::warn!(
                            "[LLMManager] Merged 2 consecutive user messages (array+array, appended {} parts)",
                            curr_len
                        );
                    }
                }
                // å‰ä¸€æ¡æ˜¯çº¯æ–‡æœ¬ï¼Œå½“å‰æ˜¯æ•°ç»„ â†’ è½¬æ¢å‰ä¸€æ¡ä¸ºæ•°ç»„åè¿½åŠ 
                (Some(serde_json::Value::String(prev_text)), Some(serde_json::Value::Array(curr_arr))) => {
                    let mut new_content = vec![json!({"type": "text", "text": prev_text})];
                    let curr_len = curr_arr.len();
                    new_content.extend(curr_arr);
                    prev["content"] = serde_json::Value::Array(new_content);
                    log::warn!(
                        "[LLMManager] Merged 2 consecutive user messages (text+array, appended {} parts)",
                        curr_len
                    );
                }
                // å‰ä¸€æ¡æ˜¯æ•°ç»„ï¼Œå½“å‰æ˜¯çº¯æ–‡æœ¬ â†’ è¿½åŠ  text å…ƒç´ 
                (Some(serde_json::Value::Array(ref _prev_arr)), Some(serde_json::Value::String(ref curr_text))) => {
                    if let Some(arr) = prev.get_mut("content").and_then(|c| c.as_array_mut()) {
                        arr.push(json!({"type": "text", "text": curr_text}));
                        log::warn!(
                            "[LLMManager] Merged 2 consecutive user messages (array+text, text_len={})",
                            curr_text.len()
                        );
                    }
                }
                // å…¶ä»–æƒ…å†µï¼ˆNone ç­‰ï¼‰â†’ ä¸åˆå¹¶ï¼Œç›´æ¥è¿½åŠ 
                _ => {
                    merged.push(msg);
                }
            }
        }

        *messages = merged;
    }

    /// ğŸ”§ C2ä¿®å¤ï¼šåˆå¹¶åºåˆ—åŒ–åçš„è¿ç»­ assistant tool_calls æ¶ˆæ¯
    ///
    /// OpenAI API è¦æ±‚åŒä¸€è½®çš„å¤šä¸ª tool_calls åœ¨ä¸€ä¸ª assistant æ¶ˆæ¯ä¸­ã€‚
    /// æ­¤å‡½æ•°åœ¨ JSON messages æ•°ç»„ä¸Šæ“ä½œï¼Œå°†è¿ç»­çš„ `{"role":"assistant","tool_calls":[...]}`
    /// æ¶ˆæ¯åˆå¹¶ä¸ºä¸€ä¸ªï¼Œå…¶ tool_calls æ•°ç»„åŒ…å«æ‰€æœ‰å·¥å…·è°ƒç”¨ã€‚
    ///
    /// åˆå¹¶è§„åˆ™ï¼š
    /// - ä»…åˆå¹¶è¿ç»­çš„ã€éƒ½åŒ…å« tool_calls çš„ assistant æ¶ˆæ¯
    /// - ä¸­é—´ä¸èƒ½æœ‰ tool/user æ¶ˆæ¯ï¼ˆé‚£è¡¨ç¤ºä¸åŒè½®æ¬¡ï¼‰
    /// - åˆå¹¶åä¿ç•™ç¬¬ä¸€ä¸ªæ¶ˆæ¯çš„ content
    pub(crate) fn merge_consecutive_assistant_tool_calls(messages: &mut Vec<serde_json::Value>) {
        if messages.len() < 2 {
            return;
        }

        let mut merged: Vec<serde_json::Value> = Vec::with_capacity(messages.len());

        for msg in messages.drain(..) {
            let is_assistant_with_tools = msg.get("role").and_then(|r| r.as_str()) == Some("assistant")
                && msg.get("tool_calls").and_then(|tc| tc.as_array()).map(|a| !a.is_empty()).unwrap_or(false);

            if !is_assistant_with_tools {
                merged.push(msg);
                continue;
            }

            // æ£€æŸ¥å‰ä¸€æ¡æ˜¯å¦ä¹Ÿæ˜¯ assistant with tool_calls
            let prev_is_assistant_with_tools = merged.last()
                .map(|m| {
                    m.get("role").and_then(|r| r.as_str()) == Some("assistant")
                        && m.get("tool_calls").and_then(|tc| tc.as_array()).map(|a| !a.is_empty()).unwrap_or(false)
                })
                .unwrap_or(false);

            if !prev_is_assistant_with_tools {
                merged.push(msg);
                continue;
            }

            // åˆå¹¶ï¼šå°†å½“å‰æ¶ˆæ¯çš„ tool_calls è¿½åŠ åˆ°å‰ä¸€æ¡
            let prev = merged.last_mut().unwrap();
            if let Some(curr_tool_calls) = msg.get("tool_calls").and_then(|tc| tc.as_array()) {
                let curr_len = curr_tool_calls.len();
                if let Some(prev_arr) = prev.get_mut("tool_calls").and_then(|tc| tc.as_array_mut()) {
                    prev_arr.extend(curr_tool_calls.clone());
                    log::debug!(
                        "[LLMManager] C2fix: Merged consecutive assistant tool_calls (+{} calls, total={})",
                        curr_len,
                        prev_arr.len()
                    );
                }
            }
        }

        *messages = merged;
    }

    /// å‘é€ä¸“ç”¨æµå¼äº‹ä»¶ï¼ˆæ ¹æ®å·¥å…·ç±»å‹å’Œcitationsçš„source_typeåˆ†ç±»ï¼‰
    fn emit_specialized_source_events(
        window: &Window,
        stream_event: &str,
        tc: &crate::models::ToolCall,
        tr: &crate::models::ToolResult,
        citations_value: &serde_json::Value,
    ) {
        if tr.ok && !citations_value.is_null() {
            if let serde_json::Value::Array(citations_array) = citations_value {
                if !citations_array.is_empty() {
                    match tc.tool_name.as_str() {
                        "web_search" => {
                            // å‘é€web_searchä¸“ç”¨æµå¼äº‹ä»¶
                            let web_search_event = json!({
                                "sources": citations_array,
                                "tool_name": "web_search",
                                "timestamp": chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string()
                            });
                            if let Err(e) = window
                                .emit(&format!("{}_web_search", stream_event), &web_search_event)
                            {
                                error!("emit web_search event failed: {}", e);
                            }
                        }
                        "rag" => {
                            // å‘é€ragä¸“ç”¨æµå¼äº‹ä»¶
                            let rag_event = json!({
                                "sources": citations_array,
                                "tool_name": "rag",
                                "timestamp": chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string()
                            });
                            if let Err(e) =
                                window.emit(&format!("{}_rag_sources", stream_event), &rag_event)
                            {
                                error!("emit rag event failed: {}", e);
                            }
                        }
                        "memory" => {
                            // å‘é€memoryä¸“ç”¨æµå¼äº‹ä»¶
                            let memory_event = json!({
                                "sources": citations_array,
                                "tool_name": "memory",
                                "timestamp": chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string()
                            });
                            if let Err(e) = window
                                .emit(&format!("{}_memory_sources", stream_event), &memory_event)
                            {
                                error!("emit memory event failed: {}", e);
                            }
                        }
                        _ => {
                            // å…¶ä»–å·¥å…·ï¼šæ ¹æ®citationsä¸­çš„source_typeè¿›è¡Œåˆ†ç±»
                            let mut web_sources = Vec::new();
                            let mut rag_sources = Vec::new();
                            let mut memory_sources = Vec::new();

                            for citation in citations_array {
                                if let Some(source_type) =
                                    citation.get("source_type").and_then(|s| s.as_str())
                                {
                                    match source_type {
                                        "search" => web_sources.push(citation.clone()),
                                        "rag" => rag_sources.push(citation.clone()),
                                        "memory" => memory_sources.push(citation.clone()),
                                        _ => rag_sources.push(citation.clone()), // é»˜è®¤å½’ç±»åˆ°rag
                                    }
                                } else {
                                    rag_sources.push(citation.clone()); // æ— source_typeé»˜è®¤å½’ç±»åˆ°rag
                                }
                            }

                            // åˆ†åˆ«å‘é€ä¸åŒç±»å‹çš„äº‹ä»¶
                            if !web_sources.is_empty() {
                                let web_search_event = json!({
                                    "sources": web_sources,
                                    "tool_name": tc.tool_name,
                                    "timestamp": chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string()
                                });
                                if let Err(e) = window.emit(
                                    &format!("{}_web_search", stream_event),
                                    &web_search_event,
                                ) {
                                    error!("emit classified web_search event failed: {}", e);
                                }
                            }
                            if !rag_sources.is_empty() {
                                let rag_event = json!({
                                    "sources": rag_sources,
                                    "tool_name": tc.tool_name,
                                    "timestamp": chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string()
                                });
                                if let Err(e) = window
                                    .emit(&format!("{}_rag_sources", stream_event), &rag_event)
                                {
                                    error!("emit classified rag event failed: {}", e);
                                }
                            }
                            if !memory_sources.is_empty() {
                                let memory_event = json!({
                                    "sources": memory_sources,
                                    "tool_name": tc.tool_name,
                                    "timestamp": chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string()
                                });
                                if let Err(e) = window.emit(
                                    &format!("{}_memory_sources", stream_event),
                                    &memory_event,
                                ) {
                                    error!("emit classified memory event failed: {}", e);
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    /// æ£€æµ‹ Gemini éæµå¼å“åº”ä¸­çš„å®‰å…¨é˜»æ–­ï¼Œå¹¶è¿”å›ç»“æ„åŒ–é”™è¯¯æ¶ˆæ¯ï¼ˆç”¨äºéæµå¼è·¯å¾„å›ä¼ ç»™å‰ç«¯ï¼‰
    pub(crate) fn extract_gemini_safety_error(resp: &serde_json::Value) -> Option<String> {
        // 1) promptFeedback.blockReason
        if let Some(obj) = resp.as_object() {
            if let Some(prompt_feedback) = obj.get("promptFeedback") {
                if let Some(block_reason) =
                    prompt_feedback.get("blockReason").and_then(|v| v.as_str())
                {
                    let info = serde_json::json!({
                        "type": "safety_error",
                        "reason": block_reason,
                        "details": prompt_feedback
                    });
                    return Some(format!("Geminiå®‰å…¨é˜»æ–­: {}", info.to_string()));
                }
            }
        }
        // 2) candidates[*].finishReason == SAFETY
        if let Some(cands) = resp.get("candidates").and_then(|v| v.as_array()) {
            for cand in cands {
                if let Some(fr) = cand.get("finishReason").and_then(|v| v.as_str()) {
                    if fr == "SAFETY" {
                        let info = serde_json::json!({
                            "type": "safety_error",
                            "reason": fr,
                            "details": cand
                        });
                        return Some(format!("Geminiå®‰å…¨é˜»æ–­: {}", info.to_string()));
                    }
                }
            }
        }
        None
    }

    /// Request cancellation for a given stream event name
    pub async fn request_cancel_stream(&self, stream_event: &str) {
        info!(
            "[LLM Manager] request_cancel_stream å¼€å§‹å¤„ç†: {}",
            stream_event
        );

        // Notify channel first (notification-style cancel)
        debug!("[LLM Manager] æ£€æŸ¥ cancel_channels...");
        if let Some(sender) = self.cancel_channels.lock().await.get(stream_event).cloned() {
            debug!("[LLM Manager] æ‰¾åˆ° cancel_channelï¼Œå‘é€å–æ¶ˆä¿¡å·...");
            if sender.send(true).is_ok() {
                info!(
                    "[LLM Manager] å–æ¶ˆä¿¡å·å·²æˆåŠŸå‘é€åˆ° channel: {}",
                    stream_event
                );
            } else {
                warn!(
                    "[LLM Manager] å–æ¶ˆä¿¡å·å‘é€å¤±è´¥ï¼ˆchannel å·²å…³é—­ï¼‰: {}",
                    stream_event
                );
            }
        } else {
            debug!(
                "[LLM Manager] æœªæ‰¾åˆ°å¯¹åº”çš„ cancel_channel: {}",
                stream_event
            );
        }

        // Fallback registry check (polling)
        debug!("[LLM Manager] å†™å…¥ cancel_registry ä½œä¸ºå¤‡ç”¨...");
        let mut guard = self.cancel_registry.lock().await;
        guard.insert(stream_event.to_string());
        debug!("[LLM Manager] å·²å°†å–æ¶ˆæ ‡è®°å†™å…¥ registry: {}", stream_event);

        debug!("[LLM Manager] request_cancel_stream å®Œæˆ");
    }

    async fn take_cancellation_if_any(&self, stream_event: &str) -> bool {
        let mut guard = self.cancel_registry.lock().await;
        if guard.remove(stream_event) {
            debug!(
                "[Cancel] Acknowledged and cleared cancel flag for stream: {}",
                stream_event
            );
            true
        } else {
            false
        }
    }

    async fn register_cancel_channel(&self, stream_event: &str) -> watch::Receiver<bool> {
        let (tx, rx) = watch::channel(false);
        self.cancel_channels
            .lock()
            .await
            .insert(stream_event.to_string(), tx);
        rx
    }

    async fn clear_cancel_channel(&self, stream_event: &str) {
        self.cancel_channels.lock().await.remove(stream_event);
    }

    /// å–æ¶ˆæ‰€æœ‰ä»¥æŸä¸ªå‰ç¼€åŒ¹é…çš„æµäº‹ä»¶ï¼ˆç”¨äºé¢˜ç›®é›†åˆ†å‰²æŒ‰ session çº§åˆ«å–æ¶ˆï¼‰
    pub async fn cancel_streams_by_prefix(&self, prefix: &str) {
        let keys: Vec<String> = self.cancel_channels.lock().await.keys().cloned().collect();
        for key in keys {
            if key.starts_with(prefix) {
                self.request_cancel_stream(&key).await;
            }
        }
        // åŒæ—¶åœ¨ registry ä¸­è½å–æ¶ˆæ ‡è®°ï¼Œé¿å… race
        let guard = self.cancel_registry.lock().await;
        for key in guard.clone().iter() {
            if key.starts_with(prefix) {
                // å·²å­˜åœ¨åˆ™å¿½ç•¥ï¼›å¦åˆ™è¿½åŠ 
            }
        }
    }

    /// åˆ›å»ºHTTPå®¢æˆ·ç«¯ï¼Œä½¿ç”¨æ¸è¿›å¼å›é€€ç­–ç•¥ç¡®ä¿å§‹ç»ˆæœ‰åˆç†çš„é…ç½®
    fn create_http_client_with_fallback() -> Client {
        // åˆ›å»ºé»˜è®¤è¯·æ±‚å¤´ï¼Œæ˜¾å¼ç¦ç”¨å‹ç¼©ï¼Œé˜²æ­¢åç«¯æ”¶åˆ° gzip/deflate æ•°æ®å¯¼è‡´ä¹±ç 
        let mut headers = HeaderMap::new();
        headers.insert("Accept-Encoding", "identity".parse().unwrap());

        // å°è¯•1: å®Œæ•´é…ç½®çš„å®¢æˆ·ç«¯ï¼ˆæ¨èé…ç½®ï¼‰
        let client_builder = ClientBuilder::new()
            .timeout(std::time::Duration::from_secs(300)) // å…¨å±€è¶…æ—¶300ç§’ï¼ˆæµå¼è¯·æ±‚éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
            .connect_timeout(std::time::Duration::from_secs(30)) // è¿æ¥è¶…æ—¶30ç§’
            .danger_accept_invalid_certs(false) // ä¿æŒSSLéªŒè¯
            .default_headers(headers.clone());

        if let Ok(client) = client_builder.build() {
            info!("HTTPå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: å®Œæ•´é…ç½®ï¼ˆè¶…æ—¶120sï¼Œè¿æ¥15sï¼Œrustls TLSï¼‰");
            return client;
        }

        // å°è¯•2: ç®€åŒ–TLSé…ç½®çš„å®¢æˆ·ç«¯
        let client_builder_2 = ClientBuilder::new()
            .timeout(std::time::Duration::from_secs(300))
            .connect_timeout(std::time::Duration::from_secs(30))
            .danger_accept_invalid_certs(false)
            .default_headers(headers.clone());

        if let Ok(client) = client_builder_2.build() {
            info!("HTTPå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: ç®€åŒ–TLSé…ç½®ï¼ˆè¶…æ—¶120sï¼Œè¿æ¥15sï¼Œç³»ç»ŸTLSï¼‰");
            return client;
        }

        // å°è¯•3: ä»…è¶…æ—¶é…ç½®çš„å®¢æˆ·ç«¯
        if let Ok(client) = ClientBuilder::new()
            .timeout(std::time::Duration::from_secs(300))
            .default_headers(headers.clone())
            .build()
        {
            info!("HTTPå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: ä»…è¶…æ—¶é…ç½®ï¼ˆè¶…æ—¶120sï¼‰");
            return client;
        }

        // å°è¯•4: æœ€å°é…ç½®çš„å®¢æˆ·ç«¯ï¼ˆä¿è¯åŸºæœ¬è¶…æ—¶ï¼‰
        if let Ok(client) = ClientBuilder::new()
            .timeout(std::time::Duration::from_secs(180)) // æœ€å°‘180ç§’è¶…æ—¶
            .default_headers(headers.clone())
            .build()
        {
            info!("HTTPå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: æœ€å°é…ç½®ï¼ˆè¶…æ—¶60sï¼‰");
            return client;
        }

        // æœ€åå›é€€: é»˜è®¤å®¢æˆ·ç«¯
        warn!("æ‰€æœ‰é…ç½®å‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤HTTPå®¢æˆ·ç«¯ï¼ˆæ— è¶…æ—¶é…ç½®ï¼‰");
        warn!("è¿™å¯èƒ½å¯¼è‡´ç½‘ç»œè¯·æ±‚æŒ‚èµ·ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿç½‘ç»œå’ŒTLSé…ç½®");
        Client::new()
    }

    /// æ£€æµ‹Base64ç¼–ç å›¾åƒçš„çœŸå®æ ¼å¼
    fn detect_image_format_from_base64(base64_data: &str) -> &'static str {
        // è§£ç Base64è·å–å‰å‡ ä¸ªå­—èŠ‚æ¥åˆ¤æ–­æ ¼å¼
        if let Ok(decoded) =
            general_purpose::STANDARD.decode(base64_data.get(..100).unwrap_or(base64_data))
        {
            Self::detect_image_format_from_bytes(&decoded)
        } else {
            "jpeg" // é»˜è®¤æ ¼å¼
        }
    }
    /// æ ¹æ®å›¾åƒå­—èŠ‚æ•°æ®æ£€æµ‹æ ¼å¼
    fn detect_image_format_from_bytes(image_data: &[u8]) -> &'static str {
        if image_data.len() < 4 {
            return "jpeg"; // é»˜è®¤æ ¼å¼
        }

        // JPEG: FF D8 FF
        if image_data.starts_with(&[0xFF, 0xD8, 0xFF]) {
            "jpeg"
        }
        // PNG: 89 50 4E 47 0D 0A 1A 0A
        else if image_data.starts_with(&[0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A]) {
            "png"
        }
        // GIF: 47 49 46 38 (GIF8)
        else if image_data.starts_with(&[0x47, 0x49, 0x46, 0x38]) {
            "gif"
        }
        // WebP: 52 49 46 46 ... 57 45 42 50 (RIFF...WEBP)
        else if image_data.len() >= 12
            && image_data.starts_with(&[0x52, 0x49, 0x46, 0x46])
            && &image_data[8..12] == &[0x57, 0x45, 0x42, 0x50]
        {
            "webp"
        }
        // BMP: 42 4D (BM)
        else if image_data.starts_with(&[0x42, 0x4D]) {
            "bmp"
        } else {
            "jpeg" // é»˜è®¤æ ¼å¼
        }
    }
    // P0ä¿®å¤ï¼šæºæŠ‘åˆ¶è®¾ç½®æ£€æŸ¥å™¨

    /// åˆå§‹åŒ–ä¾›åº”å•†ä¸æ¨¡å‹æ¡ç›®ç»“æ„ï¼Œå…¼å®¹æ—§ç‰ˆ api_configs
    pub async fn bootstrap_vendor_model_config(&self) -> Result<()> {
        let vendor_exists = self
            .db
            .get_setting("vendor_configs")
            .map_err(|e| AppError::database(format!("æ£€æµ‹ä¾›åº”å•†é…ç½®å¤±è´¥: {}", e)))?
            .is_some();
        let profile_exists = self
            .db
            .get_setting("model_profiles")
            .map_err(|e| AppError::database(format!("æ£€æµ‹æ¨¡å‹æ¡ç›®å¤±è´¥: {}", e)))?
            .is_some();

        if vendor_exists && profile_exists {
            return Ok(());
        }

        let legacy_str = self
            .db
            .get_setting("api_configs")
            .map_err(|e| AppError::database(format!("è·å–æ—§ç‰ˆAPIé…ç½®å¤±è´¥: {}", e)))?
            .unwrap_or_else(|| "[]".to_string());

        let mut legacy_configs = if legacy_str.trim().is_empty() || legacy_str.trim() == "[]" {
            Vec::new()
        } else {
            match serde_json::from_str::<Vec<ApiConfig>>(&legacy_str) {
                Ok(mut configs) => {
                    for config in &mut configs {
                        config.api_key = self.decrypt_api_key_if_needed(&config.api_key)?;
                    }
                    configs
                }
                Err(_) => {
                    info!("æ£€æµ‹åˆ°æ—§ç‰ˆAPIé…ç½®æ ¼å¼ï¼Œæ­£åœ¨è¿ç§»åˆ°ä¾›åº”å•†ç»“æ„...");
                    self.migrate_api_configs_legacy(&legacy_str).await?
                }
            }
        };

        if legacy_configs.is_empty() {
            // å³ä½¿æ—§é…ç½®ä¸ºç©ºï¼Œä¹Ÿè‡³å°‘è¦åˆå§‹åŒ–ç©ºæ•°ç»„ï¼Œä¾¿äºåç»­å†™å…¥
            self.save_vendor_model_configs(&[], &[]).await?;
            return Ok(());
        }

        let (mut vendors, mut profiles) = self
            .flatten_api_configs_to_vendor_profiles(&legacy_configs)
            .await?;
        legacy_configs.clear();

        // è¿ç§»æ—¶ä¸¢å¼ƒå†…ç½®é…ç½®ï¼Œç”±è¿è¡Œæ—¶åŠ¨æ€æ³¨å…¥
        vendors.retain(|v| !v.is_builtin);
        profiles.retain(|p| !p.is_builtin);

        self.save_vendor_model_configs(&vendors, &profiles).await?;
        Ok(())
    }

    pub async fn get_vendor_configs(&self) -> Result<Vec<VendorConfig>> {
        self.bootstrap_vendor_model_config().await?;
        let mut vendors = self.read_user_vendor_configs().await?;
        if let Ok((builtin_vendors, _)) = self.load_builtin_vendor_profiles() {
            for mut vendor in builtin_vendors {
                if let Some(existing) = vendors.iter_mut().find(|v| v.id == vendor.id) {
                    // åŒæ­¥å†…ç½®ä¾›åº”å•†çš„ä¿¡æ¯å­—æ®µï¼Œä¿ç•™ç”¨æˆ·è‡ªå®šä¹‰çš„ base_url/headers ç­‰
                    existing.notes = vendor.notes.clone();
                    existing.name = vendor.name.clone();
                    existing.website_url = vendor.website_url.clone();
                    existing.is_builtin = true;
                    continue;
                }
                vendor.api_key = String::new();
                vendors.push(vendor);
            }
        }
        // ç»Ÿä¸€å¤„ç†ï¼šå†…ç½®ä¾›åº”å•†ä»å®‰å…¨å­˜å‚¨è¯»å–çœŸå® API keyï¼ˆä¸ vendor_configs_for_runtime ä¸€è‡´ï¼‰
        // å‰ç«¯å¯ç›´æ¥åœ¨ password input ä¸­æ˜¾ç¤ºå¯†ç ç‚¹ï¼Œè€Œéä»…æ˜¾ç¤º"å·²é…ç½®"å ä½ç¬¦ã€‚
        for vendor in &mut vendors {
            let is_builtin_vendor = vendor.is_builtin || vendor.id.starts_with("builtin-");
            if !is_builtin_vendor {
                continue;
            }
            let is_invalid = vendor.api_key.is_empty()
                || vendor.api_key == "***"
                || vendor.api_key.chars().all(|c| c == '*');
            if is_invalid {
                let secret_key = format!("{}.api_key", vendor.id);
                if let Ok(Some(key)) = self.db.get_secret(&secret_key) {
                    if !key.is_empty() {
                        vendor.api_key = key;
                    }
                }
                // å…¼å®¹æ—§çš„ SiliconFlow å­˜å‚¨æ ¼å¼
                if vendor.id == "builtin-siliconflow" && vendor.api_key.is_empty() {
                    if let Ok(Some(sf_key)) = self.db.get_secret("siliconflow.api_key") {
                        if !sf_key.is_empty() {
                            vendor.api_key = sf_key;
                        }
                    }
                }
            }
            vendor.is_builtin = true;
        }
        Ok(vendors)
    }

    async fn read_user_vendor_configs(&self) -> Result<Vec<VendorConfig>> {
        let raw = self
            .db
            .get_setting("vendor_configs")
            .map_err(|e| AppError::database(format!("è·å–ä¾›åº”å•†é…ç½®å¤±è´¥: {}", e)))?
            .unwrap_or_else(|| "[]".to_string());

        let mut vendors: Vec<VendorConfig> = serde_json::from_str(&raw)
            .map_err(|e| AppError::configuration(format!("è§£æä¾›åº”å•†é…ç½®å¤±è´¥: {}", e)))?;

        // å®¹é”™å¤„ç†ï¼šè§£å¯†å¤±è´¥æ—¶æ¸…ç©º API å¯†é’¥è€Œä¸æ˜¯è®©æ•´ä¸ªé…ç½®åŠ è½½å¤±è´¥
        for vendor in &mut vendors {
            match self.decrypt_api_key_if_needed(&vendor.api_key) {
                Ok(decrypted) => {
                    // è¿ç§»é€»è¾‘ï¼šå¦‚æœæ˜¯å†…ç½®ä¾›åº”å•†ä¸”æˆåŠŸè§£å¯†äº† API keyï¼Œè¿ç§»åˆ°å®‰å…¨å­˜å‚¨
                    let is_builtin_vendor = vendor.is_builtin || vendor.id.starts_with("builtin-");
                    if is_builtin_vendor && !decrypted.is_empty() {
                        let secret_key = format!("{}.api_key", vendor.id);
                        if let Err(e) = self.db.save_secret(&secret_key, &decrypted) {
                            tracing::warn!(
                                "âš ï¸ è¿ç§»å†…ç½®ä¾›åº”å•† {} çš„ API å¯†é’¥åˆ°å®‰å…¨å­˜å‚¨å¤±è´¥: {}",
                                vendor.id,
                                e
                            );
                        } else {
                            tracing::info!(
                                "âœ… å·²è¿ç§»å†…ç½®ä¾›åº”å•† {} çš„ API å¯†é’¥åˆ°å®‰å…¨å­˜å‚¨",
                                vendor.id
                            );
                        }
                        // è¿ç§»åä¸å†å‘ä¸Šæ¸¸è¿”å›æ˜æ–‡ï¼ˆè¿è¡ŒæœŸä¼šä»å®‰å…¨å­˜å‚¨è¯»å–ï¼‰
                        vendor.api_key = String::new();
                        vendor.is_builtin = true;
                        continue;
                    }
                    vendor.api_key = decrypted;
                }
                Err(e) => {
                    // è®°å½•è­¦å‘Šä½†ä¸ä¸­æ–­åŠ è½½
                    tracing::warn!(
                        "âš ï¸ ä¾›åº”å•† {} çš„ API å¯†é’¥è§£å¯†å¤±è´¥ï¼Œå°†æ¸…ç©ºå¯†é’¥: {}",
                        vendor.id,
                        e
                    );
                    // æ¸…ç©ºå¯†é’¥ï¼Œç”¨æˆ·éœ€è¦é‡æ–°é…ç½®
                    vendor.api_key = String::new();
                }
            }
        }
        Ok(vendors)
    }

    async fn vendor_configs_for_runtime(&self) -> Result<Vec<VendorConfig>> {
        let mut vendors = self.read_user_vendor_configs().await?;
        if let Ok((builtin_vendors, _)) = self.load_builtin_vendor_profiles() {
            for vendor in builtin_vendors {
                if vendors.iter().any(|v| v.id == vendor.id) {
                    continue;
                }
                vendors.push(vendor);
            }
        }

        // å†…ç½®ä¾›åº”å•†çš„ API key ç»Ÿä¸€é€šè¿‡å®‰å…¨å­˜å‚¨ç®¡ç†ï¼ˆé¿å…ä¸»å¯†é’¥ä¸ç¨³å®šå¯¼è‡´çš„è§£å¯†é—®é¢˜ï¼‰
        // å­˜å‚¨æ ¼å¼ï¼š{vendor_id}.api_keyï¼Œå¦‚ "builtin-siliconflow.api_key"
        // æ³¨æ„ï¼šä½¿ç”¨ vendor.id.starts_with("builtin-") åˆ¤æ–­ï¼Œè€Œä¸æ˜¯ is_builtin å­—æ®µ
        // å› ä¸ºæ—§æ•°æ®å¯èƒ½æœ‰ is_builtin=false çš„å†…ç½®ä¾›åº”å•†
        for vendor in &mut vendors {
            let is_builtin_vendor = vendor.is_builtin || vendor.id.starts_with("builtin-");
            if is_builtin_vendor {
                let is_invalid = vendor.api_key.is_empty()
                    || vendor.api_key == "***"
                    || vendor.api_key.chars().all(|c| c == '*');
                if is_invalid {
                    // ä»å®‰å…¨å­˜å‚¨è¯»å– API key
                    let secret_key = format!("{}.api_key", vendor.id);
                    if let Ok(Some(key)) = self.db.get_secret(&secret_key) {
                        if !key.is_empty() {
                            vendor.api_key = key;
                        }
                    }
                    // å…¼å®¹æ—§çš„ SiliconFlow å­˜å‚¨æ ¼å¼
                    if vendor.id == "builtin-siliconflow" && vendor.api_key.is_empty() {
                        if let Ok(Some(sf_key)) = self.db.get_secret("siliconflow.api_key") {
                            if !sf_key.is_empty() {
                                vendor.api_key = sf_key;
                            }
                        }
                    }
                }
                // ç¡®ä¿ is_builtin å­—æ®µæ­£ç¡®ï¼ˆä¿®å¤æ—§æ•°æ®ï¼‰
                vendor.is_builtin = true;
            }
        }

        Ok(vendors)
    }

    pub async fn save_vendor_configs(&self, configs: &[VendorConfig]) -> Result<()> {
        // è¯»å–ç°æœ‰é…ç½®ï¼Œç”¨äºä¿ç•™æœªæ›´æ–°çš„ API key
        let existing_vendors = self.read_user_vendor_configs().await.unwrap_or_default();
        let existing_map: std::collections::HashMap<String, String> = existing_vendors
            .into_iter()
            .map(|v| (v.id.clone(), v.api_key))
            .collect();

        let mut sanitized = Vec::new();
        for cfg in configs {
            let mut clone = cfg.clone();

            let trimmed = cfg.api_key.trim();
            // â€œä¿ç•™æ—§å€¼â€å ä½ç¬¦ï¼š*** æˆ–å…¨ *ï¼ˆä½†ä¸åŒ…å«ç©ºå­—ç¬¦ä¸²ï¼‰
            // ç©ºå­—ç¬¦ä¸²åº”è§†ä¸ºç”¨æˆ·æ˜ç¡®æ¸…ç©ºï¼ˆè€Œä¸æ˜¯ä¿ç•™ï¼‰ã€‚
            let keep_placeholder =
                trimmed == "***" || (!trimmed.is_empty() && trimmed.chars().all(|c| c == '*'));
            // å†…ç½®ä¾›åº”å•†åˆ¤æ–­ï¼šå…¼å®¹æ—§æ•°æ®ï¼ˆis_builtin=false ä½† id ä»¥ builtin- å¼€å¤´ï¼‰
            let is_builtin_vendor = cfg.is_builtin || cfg.id.starts_with("builtin-");

            if is_builtin_vendor {
                // å†…ç½®ä¾›åº”å•†ï¼šAPI key å§‹ç»ˆé€šè¿‡å®‰å…¨å­˜å‚¨ç®¡ç†ï¼Œvendor_configs ä¸­ä¸ä¿å­˜
                let secret_key = format!("{}.api_key", cfg.id);
                if keep_placeholder {
                    // no-opï¼šä¿ç•™å®‰å…¨å­˜å‚¨ä¸­çš„å€¼
                } else if trimmed.is_empty() {
                    // ç”¨æˆ·æ˜ç¡®æ¸…ç©ºï¼šåˆ é™¤å®‰å…¨å­˜å‚¨ä¸­çš„å¯†é’¥
                    let _ = self.db.delete_secret(&secret_key);
                    // å…¼å®¹æ—§çš„ SiliconFlow å­˜å‚¨æ ¼å¼
                    if cfg.id == "builtin-siliconflow" {
                        let _ = self.db.delete_secret("siliconflow.api_key");
                    }
                } else {
                    self.db.save_secret(&secret_key, trimmed).map_err(|e| {
                        AppError::database(format!("ä¿å­˜å†…ç½®ä¾›åº”å•†APIå¯†é’¥å¤±è´¥: {}", e))
                    })?;
                }
                clone.api_key = String::new();
                clone.is_builtin = true;
            } else {
                // éå†…ç½®ä¾›åº”å•†ï¼šAPI key åŠ å¯†å­˜å‚¨åˆ° vendor_configs
                let effective_api_key = if keep_placeholder {
                    existing_map.get(&cfg.id).cloned().unwrap_or_default()
                } else {
                    trimmed.to_string()
                };
                clone.api_key = self.encrypt_api_key(&effective_api_key)?;
                clone.is_read_only = false;
            }
            sanitized.push(clone);
        }

        let json = serde_json::to_string(&sanitized)
            .map_err(|e| AppError::configuration(format!("åºåˆ—åŒ–ä¾›åº”å•†é…ç½®å¤±è´¥: {}", e)))?;
        self.db
            .save_setting("vendor_configs", &json)
            .map_err(|e| AppError::database(format!("ä¿å­˜ä¾›åº”å•†é…ç½®å¤±è´¥: {}", e)))?;
        Ok(())
    }

    pub async fn get_model_profiles(&self) -> Result<Vec<ModelProfile>> {
        self.bootstrap_vendor_model_config().await?;
        let mut profiles = self.read_user_model_profiles().await?;

        // ä¸€æ¬¡æ€§è¿ç§»ï¼šç›´æ¥å°†å†…ç½®æ¨¡å‹çš„èƒ½åŠ›å­—æ®µå†™å…¥ç”¨æˆ·å­˜å‚¨çš„ model_profilesã€‚
        // èƒŒæ™¯ï¼šæ—©æœŸç‰ˆæœ¬åœ¨æ— å¿«ç…§æ—¶ä¿å®ˆåœ°ä¿ç•™äº†ç”¨æˆ·æ•°æ®ï¼ˆå«é”™è¯¯çš„ supports_tools=falseï¼‰ï¼Œ
        // éšåå¿«ç…§è¢«"æ±¡æŸ“"ä¸ºæ–°å†…ç½®å€¼ï¼Œå¯¼è‡´åç»­åˆå¹¶æ°¸è¿œè·³è¿‡æ›´æ–°ã€‚
        // å¿…é¡»ç›´æ¥ä¿®æ”¹ DB ä¸­çš„ model_profilesï¼Œå¦åˆ™è¿è¡Œæ—¶è·¯å¾„ï¼ˆmodel_profiles_for_runtimeï¼‰
        // ä»ä¼šè¯»åˆ°æ—§å€¼ã€‚
        const BUILTIN_CAPS_MIGRATION_KEY: &str = "builtin_caps_migration_v2";
        if self.db.get_setting(BUILTIN_CAPS_MIGRATION_KEY).ok().flatten().is_none() {
            if let Ok((_, builtin_list)) = self.load_builtin_vendor_profiles() {
                let builtin_map: HashMap<String, &ModelProfile> =
                    builtin_list.iter().map(|p| (p.id.clone(), p)).collect();
                let mut patched = false;
                for profile in &mut profiles {
                    if let Some(builtin) = builtin_map.get(&profile.id) {
                        if profile.supports_tools != builtin.supports_tools
                            || profile.is_multimodal != builtin.is_multimodal
                            || profile.is_reasoning != builtin.is_reasoning
                            || profile.supports_reasoning != builtin.supports_reasoning
                        {
                            profile.is_multimodal = builtin.is_multimodal;
                            profile.is_reasoning = builtin.is_reasoning;
                            profile.is_embedding = builtin.is_embedding;
                            profile.is_reranker = builtin.is_reranker;
                            profile.supports_tools = builtin.supports_tools;
                            profile.supports_reasoning = builtin.supports_reasoning;
                            patched = true;
                            info!(
                                "[VendorModel] è¿ç§»: {} èƒ½åŠ›å­—æ®µå·²ä»å†…ç½®å®šä¹‰åŒæ­¥ (supports_tools={})",
                                profile.id, builtin.supports_tools
                            );
                        }
                    }
                }
                if patched {
                    if let Err(e) = self.save_model_profiles(&profiles).await {
                        warn!("[VendorModel] è¿ç§»ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“æœ¬æ¬¡è¯»å–ï¼‰: {}", e);
                    }
                }
            }
            // åŒæ—¶æ¸…é™¤å¿«ç…§ï¼Œè®©åç»­ merge åŸºäºå¹²å‡€çŠ¶æ€é‡å»º
            let _ = self.db.save_setting(BUILTIN_MODEL_PROFILES_SNAPSHOT_KEY, "[]");
            let _ = self.db.save_setting(BUILTIN_CAPS_MIGRATION_KEY, "done");
            info!("[VendorModel] èƒ½åŠ›å­—æ®µè¿ç§»å®Œæˆ");
        }

        let snapshot_map = self.read_builtin_profile_snapshot_map();
        if let Ok((_, builtin_profiles)) = self.load_builtin_vendor_profiles() {
            for builtin_profile in &builtin_profiles {
                Self::merge_builtin_profile_user_aware(
                    &mut profiles,
                    builtin_profile.clone(),
                    snapshot_map.get(&builtin_profile.id),
                );
            }
            if let Err(err) = self.save_builtin_profile_snapshot(&builtin_profiles) {
                warn!("[VendorModel] ä¿å­˜å†…ç½®æ¨¡å‹å¿«ç…§å¤±è´¥ï¼ˆä¸å½±å“è¯»å–ï¼‰: {}", err);
            }
        }
        Ok(profiles)
    }

    async fn read_user_model_profiles(&self) -> Result<Vec<ModelProfile>> {
        let raw = self
            .db
            .get_setting("model_profiles")
            .map_err(|e| AppError::database(format!("è·å–æ¨¡å‹æ¡ç›®å¤±è´¥: {}", e)))?
            .unwrap_or_else(|| "[]".to_string());

        let profiles: Vec<ModelProfile> = serde_json::from_str(&raw)
            .map_err(|e| AppError::configuration(format!("è§£ææ¨¡å‹æ¡ç›®å¤±è´¥: {}", e)))?;
        Ok(profiles)
    }

    async fn model_profiles_for_runtime(&self) -> Result<Vec<ModelProfile>> {
        // å¤ç”¨ get_model_profiles ä»¥ç¡®ä¿è¿è¡Œæ—¶è·¯å¾„ä¹Ÿæ‰§è¡Œèƒ½åŠ›å­—æ®µè¿ç§»å’Œå¿«ç…§åˆå¹¶
        self.get_model_profiles().await
    }

    pub async fn save_model_profiles(&self, profiles: &[ModelProfile]) -> Result<()> {
        // â˜… 2026-01-19 ä¿®å¤ï¼šä¿å­˜æ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬ is_builtin=trueï¼‰ï¼Œä»¥æ”¯æŒç”¨æˆ·å¯¹å†…ç½®æ¨¡å‹çš„æ”¶è—ç­‰è‡ªå®šä¹‰è®¾ç½®
        // åŠ è½½æ—¶æŒ‰â€œå­—æ®µçº§ç”¨æˆ·ä¼˜å…ˆâ€è¿›è¡Œåˆå¹¶ï¼šç”¨æˆ·æ”¹è¿‡çš„å­—æ®µä¿æŒä¸å˜ï¼Œæœªæ”¹å­—æ®µå¯æ¥æ”¶åç»­å†…ç½®æ›´æ–°
        let json = serde_json::to_string(profiles)
            .map_err(|e| AppError::configuration(format!("åºåˆ—åŒ–æ¨¡å‹æ¡ç›®å¤±è´¥: {}", e)))?;
        self.db
            .save_setting("model_profiles", &json)
            .map_err(|e| AppError::database(format!("ä¿å­˜æ¨¡å‹æ¡ç›®å¤±è´¥: {}", e)))?;
        Ok(())
    }

    pub async fn save_vendor_model_configs(
        &self,
        vendors: &[VendorConfig],
        profiles: &[ModelProfile],
    ) -> Result<()> {
        self.save_vendor_configs(vendors).await?;
        self.save_model_profiles(profiles).await?;
        Ok(())
    }

    /// å‘åå…¼å®¹çš„ ApiConfig åˆ—è¡¨ï¼ˆè¿è¡ŒæœŸå·²é™„å¸¦ä¾›åº”å•†ä¿¡æ¯ï¼‰
    pub async fn get_api_configs(&self) -> Result<Vec<ApiConfig>> {
        self.bootstrap_vendor_model_config().await?;
        let vendors = self.vendor_configs_for_runtime().await?;
        let profiles = self.model_profiles_for_runtime().await?;
        let vendor_map: HashMap<String, VendorConfig> =
            vendors.into_iter().map(|v| (v.id.clone(), v)).collect();

        let mut resolved = Vec::new();
        for profile in profiles {
            if let Some(vendor) = vendor_map.get(&profile.vendor_id) {
                let merged = self.merge_vendor_profile(vendor, &profile)?;
                resolved.push(merged.runtime);
            } else {
                warn!("[VendorModel] æ‰¾ä¸åˆ°æ¨¡å‹æ¡ç›®å…³è”çš„ä¾›åº”å•†: {}", profile.id);
            }
        }

        Ok(resolved)
    }

    fn merge_vendor_profile(
        &self,
        vendor: &VendorConfig,
        profile: &ModelProfile,
    ) -> Result<ResolvedModelConfig> {
        let api_key = if vendor.is_builtin {
            vendor.api_key.trim().to_string()
        } else {
            self.decrypt_api_key_if_needed(&vendor.api_key)?
                .trim()
                .to_string()
        };

        let has_api_key =
            !api_key.is_empty() && api_key != "***" && !api_key.chars().all(|c| c == '*');

        let runtime = ApiConfig {
            id: profile.id.clone(),
            name: profile.label.clone(),
            vendor_id: Some(vendor.id.clone()),
            vendor_name: Some(vendor.name.clone()),
            provider_type: Some(vendor.provider_type.clone()),
            api_key,
            base_url: vendor.base_url.clone(),
            model: profile.model.clone(),
            is_multimodal: profile.is_multimodal,
            is_reasoning: profile.is_reasoning,
            is_embedding: profile.is_embedding,
            is_reranker: profile.is_reranker,
            enabled: profile.enabled && profile.status.to_lowercase() != "disabled" && has_api_key,
            model_adapter: profile.model_adapter.clone(),
            max_output_tokens: profile.max_output_tokens,
            temperature: profile.temperature,
            supports_tools: profile.supports_tools,
            gemini_api_version: profile
                .gemini_api_version
                .clone()
                .unwrap_or_else(default_gemini_api_version),
            is_builtin: profile.is_builtin || vendor.is_builtin,
            is_read_only: vendor.is_read_only,
            reasoning_effort: profile.reasoning_effort.clone(),
            thinking_enabled: profile.thinking_enabled,
            thinking_budget: profile.thinking_budget,
            include_thoughts: profile.include_thoughts,
            min_p: profile.min_p,
            top_k: profile.top_k,
            enable_thinking: profile.enable_thinking,
            supports_reasoning: profile.supports_reasoning || profile.is_reasoning,
            headers: Some(vendor.headers.clone()),
            top_p_override: None,
            frequency_penalty_override: None,
            presence_penalty_override: None,
            repetition_penalty: profile.repetition_penalty,
            reasoning_split: profile.reasoning_split,
            effort: profile.effort.clone(),
            verbosity: profile.verbosity.clone(),
            is_favorite: profile.is_favorite,
            // æ¨¡å‹ç²’åº¦è‡ªç®¡ç† max_tokens_limitï¼Œä¸ä»ä¾›åº”å•†ç»§æ‰¿
            max_tokens_limit: profile.max_tokens_limit,
        };

        Ok(ResolvedModelConfig {
            vendor: vendor.clone(),
            profile: profile.clone(),
            runtime,
        })
    }

    fn load_builtin_vendor_profiles(&self) -> Result<(Vec<VendorConfig>, Vec<ModelProfile>)> {
        let mut vendors = Vec::new();
        let mut profiles = Vec::new();

        // 1. é¦–å…ˆåŠ è½½å†…ç½®å…è´¹æ¨¡å‹ï¼ˆå¦‚æœæœ‰ç¼–è¯‘æ—¶ç¯å¢ƒå˜é‡ï¼‰
        let builtin = match load_builtin_api_configs() {
            Ok(configs) => configs,
            Err(err) => {
                error!("[VendorModel] åŠ è½½å†…ç½®æ¨¡å‹é…ç½®å¤±è´¥: {}", err);
                Vec::new()
            }
        };
        for cfg in builtin {
            let is_siliconflow = cfg.base_url.to_lowercase().contains("siliconflow");
            let vendor_id = if is_siliconflow {
                "builtin-siliconflow".to_string()
            } else {
                format!("builtin-{}", cfg.id)
            };
            let vendor_name = if is_siliconflow {
                "SiliconFlow".to_string()
            } else {
                cfg.name.clone()
            };
            if !vendors.iter().any(|v: &VendorConfig| v.id == vendor_id) {
                vendors.push(VendorConfig {
                    id: vendor_id.clone(),
                    name: vendor_name,
                    provider_type: if is_siliconflow {
                        "siliconflow".to_string()
                    } else {
                        cfg.model_adapter.clone()
                    },
                    base_url: cfg.base_url.clone(),
                    api_key: cfg.api_key.clone(),
                    headers: cfg.headers.clone().unwrap_or_default(),
                    rate_limit_per_minute: None,
                    default_timeout_ms: None,
                    notes: None,
                    is_builtin: true,
                    is_read_only: true,
                    sort_order: None,
                    max_tokens_limit: cfg.max_tokens_limit,
                    website_url: None,
                });
            }
            profiles.push(ModelProfile {
                id: cfg.id.clone(),
                vendor_id: vendor_id.clone(),
                label: cfg.name.clone(),
                model: cfg.model.clone(),
                model_adapter: cfg.model_adapter.clone(),
                is_multimodal: cfg.is_multimodal,
                is_reasoning: cfg.is_reasoning,
                is_embedding: cfg.is_embedding,
                is_reranker: cfg.is_reranker,
                supports_tools: cfg.supports_tools,
                supports_reasoning: cfg.supports_reasoning || cfg.is_reasoning,
                status: if cfg.enabled {
                    "enabled".to_string()
                } else {
                    "disabled".to_string()
                },
                enabled: cfg.enabled,
                max_output_tokens: cfg.max_output_tokens,
                temperature: cfg.temperature,
                reasoning_effort: cfg.reasoning_effort.clone(),
                thinking_enabled: cfg.thinking_enabled,
                thinking_budget: cfg.thinking_budget,
                include_thoughts: cfg.include_thoughts,
                enable_thinking: cfg.enable_thinking,
                min_p: cfg.min_p,
                top_k: cfg.top_k,
                gemini_api_version: Some(cfg.gemini_api_version.clone()),
                is_builtin: true,
                is_favorite: cfg.is_favorite,
                max_tokens_limit: cfg.max_tokens_limit,
                repetition_penalty: cfg.repetition_penalty,
                reasoning_split: cfg.reasoning_split,
                effort: cfg.effort.clone(),
                verbosity: cfg.verbosity.clone(),
            });
        }

        // 2. åŠ è½½é¢„ç½®ä¾›åº”å•†æ¨¡æ¿ï¼ˆæ¥è‡ª builtin_vendors æ¨¡å—ï¼‰
        let existing_vendor_ids: Vec<String> = vendors.iter().map(|v| v.id.clone()).collect();
        let existing_profile_ids: Vec<String> = profiles.iter().map(|p| p.id.clone()).collect();

        let (new_vendors, new_profiles) =
            builtin_vendors::load_all_builtins(&existing_vendor_ids, &existing_profile_ids);

        vendors.extend(new_vendors);
        profiles.extend(new_profiles);

        Ok((vendors, profiles))
    }

    // è¿ç§»æ—§ç‰ˆAPIé…ç½®åˆ°æ–°ç»“æ„ï¼ˆå…¼å®¹è¯»å–ï¼‰
    async fn migrate_api_configs_legacy(&self, old_config_str: &str) -> Result<Vec<ApiConfig>> {
        #[derive(serde::Deserialize)]
        struct OldApiConfigV2 {
            id: String,
            name: String,
            api_key: String,
            base_url: String,
            model: String,
            is_multimodal: bool,
            is_reasoning: bool,
            enabled: bool,
        }

        #[derive(serde::Deserialize)]
        struct OldApiConfigV1 {
            id: String,
            name: String,
            api_key: String,
            base_url: String,
            model: String,
            is_multimodal: bool,
            enabled: bool,
        }

        if let Ok(old_configs) = serde_json::from_str::<Vec<OldApiConfigV2>>(old_config_str) {
            return Ok(old_configs
                .into_iter()
                .map(|old| ApiConfig {
                    id: old.id,
                    name: old.name,
                    api_key: old.api_key,
                    base_url: old.base_url,
                    model: old.model,
                    is_multimodal: old.is_multimodal,
                    is_reasoning: old.is_reasoning,
                    is_embedding: false,
                    is_reranker: false,
                    enabled: old.enabled,
                    model_adapter: default_model_adapter(),
                    max_output_tokens: default_max_output_tokens(),
                    temperature: default_temperature(),
                    supports_tools: false,
                    gemini_api_version: default_gemini_api_version(),
                    min_p: None,
                    top_k: None,
                    enable_thinking: None,
                    is_builtin: false,
                    is_read_only: false,
                    reasoning_effort: None,
                    thinking_enabled: false,
                    thinking_budget: None,
                    include_thoughts: false,
                    supports_reasoning: old.is_reasoning,
                    vendor_id: None,
                    vendor_name: None,
                    provider_type: None,
                    headers: None,
                    top_p_override: None,
                    frequency_penalty_override: None,
                    presence_penalty_override: None,
                    repetition_penalty: None,
                    reasoning_split: None,
                    effort: None,
                    verbosity: None,
                    is_favorite: false,
                    max_tokens_limit: None,
                })
                .collect());
        }

        let old_configs: Vec<OldApiConfigV1> = serde_json::from_str(old_config_str)
            .map_err(|e| AppError::configuration(format!("è§£ææ—§ç‰ˆAPIé…ç½®å¤±è´¥: {}", e)))?;

        Ok(old_configs
            .into_iter()
            .map(|old| ApiConfig {
                id: old.id,
                name: old.name,
                api_key: old.api_key,
                base_url: old.base_url,
                model: old.model,
                is_multimodal: old.is_multimodal,
                is_reasoning: false,
                is_embedding: false,
                is_reranker: false,
                enabled: old.enabled,
                model_adapter: default_model_adapter(),
                max_output_tokens: default_max_output_tokens(),
                temperature: default_temperature(),
                supports_tools: false,
                gemini_api_version: default_gemini_api_version(),
                min_p: None,
                top_k: None,
                enable_thinking: None,
                is_builtin: false,
                is_read_only: false,
                reasoning_effort: None,
                thinking_enabled: false,
                thinking_budget: None,
                include_thoughts: false,
                supports_reasoning: false,
                vendor_id: None,
                vendor_name: None,
                provider_type: None,
                headers: None,
                top_p_override: None,
                frequency_penalty_override: None,
                presence_penalty_override: None,
                is_favorite: false,
                max_tokens_limit: None,
                repetition_penalty: None,
                reasoning_split: None,
                effort: None,
                verbosity: None,
            })
            .collect())
    }

    async fn flatten_api_configs_to_vendor_profiles(
        &self,
        configs: &[ApiConfig],
    ) -> Result<(Vec<VendorConfig>, Vec<ModelProfile>)> {
        let mut vendors_map: HashMap<String, VendorConfig> = HashMap::new();
        let mut profiles: Vec<ModelProfile> = Vec::new();

        for cfg in configs {
            let base_key = format!("{}::{}", cfg.base_url.trim(), cfg.api_key.trim());
            let key = cfg
                .vendor_id
                .clone()
                .unwrap_or_else(|| format!("auto::{}", base_key));
            let vendor_entry = vendors_map.entry(key.clone()).or_insert_with(|| {
                let provider_type = cfg
                    .provider_type
                    .clone()
                    .unwrap_or_else(|| cfg.model_adapter.clone());
                let vendor_id = cfg
                    .vendor_id
                    .clone()
                    .or_else(|| Some(format!("vendor-{}", Uuid::new_v4())))
                    .unwrap();
                VendorConfig {
                    id: vendor_id,
                    name: cfg
                        .vendor_name
                        .clone()
                        .filter(|name| !name.is_empty())
                        .unwrap_or_else(|| cfg.name.clone()),
                    provider_type,
                    base_url: cfg.base_url.clone(),
                    api_key: cfg.api_key.clone(),
                    headers: cfg.headers.clone().unwrap_or_default(),
                    rate_limit_per_minute: None,
                    default_timeout_ms: None,
                    notes: None,
                    is_builtin: cfg.is_builtin,
                    is_read_only: cfg.is_read_only,
                    sort_order: None,
                    max_tokens_limit: cfg.max_tokens_limit,
                    website_url: None,
                }
            });
            let vendor_id = vendor_entry.id.clone();

            profiles.push(ModelProfile {
                id: cfg.id.clone(),
                vendor_id,
                label: cfg.name.clone(),
                model: cfg.model.clone(),
                model_adapter: cfg.model_adapter.clone(),
                is_multimodal: cfg.is_multimodal,
                is_reasoning: cfg.is_reasoning,
                is_embedding: cfg.is_embedding,
                is_reranker: cfg.is_reranker,
                supports_tools: cfg.supports_tools,
                supports_reasoning: cfg.supports_reasoning || cfg.is_reasoning,
                status: if cfg.enabled {
                    "enabled".to_string()
                } else {
                    "disabled".to_string()
                },
                enabled: cfg.enabled,
                max_output_tokens: cfg.max_output_tokens,
                temperature: cfg.temperature,
                reasoning_effort: cfg.reasoning_effort.clone(),
                thinking_enabled: cfg.thinking_enabled,
                thinking_budget: cfg.thinking_budget,
                include_thoughts: cfg.include_thoughts,
                enable_thinking: cfg.enable_thinking,
                min_p: cfg.min_p,
                top_k: cfg.top_k,
                gemini_api_version: Some(cfg.gemini_api_version.clone()),
                is_builtin: cfg.is_builtin,
                is_favorite: cfg.is_favorite,
                max_tokens_limit: cfg.max_tokens_limit,
                repetition_penalty: cfg.repetition_penalty,
                reasoning_split: cfg.reasoning_split,
                effort: cfg.effort.clone(),
                verbosity: cfg.verbosity.clone(),
            });
        }

        Ok((vendors_map.into_values().collect(), profiles))
    }
    // è·å–å¯¹è¯æ¨¡å‹é…ç½®ï¼ˆå…¬å¼€æ–¹æ³•ï¼‰
    pub async fn get_model2_config(&self) -> Result<ApiConfig> {
        let assignments = self.get_model_assignments().await?;
        let model2_id = assignments
            .model2_config_id
            .ok_or_else(|| AppError::configuration("å¯¹è¯æ¨¡å‹æœªé…ç½®"))?;

        let configs = self.get_api_configs().await?;
        // æ³¨æ„ï¼šå·²åˆ†é…çš„æ¨¡å‹å³ä½¿ enabled=false ä¹Ÿå…è®¸ä½¿ç”¨
        // enabled ä»…å½±å“æ¨¡å‹é€‰æ‹©å™¨ä¸­çš„æ˜¾ç¤ºï¼Œä¸é˜»æ­¢å·²åˆ†é…æ¨¡å‹çš„è°ƒç”¨
        let config = configs
            .into_iter()
            .find(|c| c.id == model2_id && !c.is_embedding && !c.is_reranker)
            .ok_or_else(|| {
                AppError::configuration(
                    "æ‰¾ä¸åˆ°æœ‰æ•ˆçš„å¯¹è¯æ¨¡å‹é…ç½®ï¼ˆç¦æ­¢ä½¿ç”¨åµŒå…¥/é‡æ’åºæ¨¡å‹ä½œä¸ºå¯¹è¯æ¨¡å‹ï¼‰",
                )
            })?;

        Ok(config)
    }

    /// è·å–è®°å¿†å†³ç­–æ¨¡å‹é…ç½®ï¼ˆå…¬å¼€æ–¹æ³•ï¼‰
    ///
    /// å›é€€é“¾ï¼šmemory_decision_model_config_id â†’ model2_config_id
    pub async fn get_memory_decision_model_config(&self) -> Result<ApiConfig> {
        let assignments = self.get_model_assignments().await?;
        let model_id = assignments
            .memory_decision_model_config_id
            .or(assignments.model2_config_id)
            .ok_or_else(|| AppError::configuration("æ²¡æœ‰é…ç½®å¯ç”¨çš„è®°å¿†å†³ç­–æ¨¡å‹"))?;

        let configs = self.get_api_configs().await?;
        let config = configs
            .into_iter()
            .find(|c| c.id == model_id && !c.is_embedding && !c.is_reranker)
            .ok_or_else(|| {
                AppError::configuration(
                    "æ‰¾ä¸åˆ°æœ‰æ•ˆçš„è®°å¿†å†³ç­–æ¨¡å‹é…ç½®ï¼ˆç¦æ­¢ä½¿ç”¨åµŒå…¥/é‡æ’åºæ¨¡å‹ï¼‰",
                )
            })?;

        Ok(config)
    }

    /// è·å–æ ‡é¢˜/æ ‡ç­¾ç”Ÿæˆæ¨¡å‹é…ç½®ï¼ˆå…¬å¼€æ–¹æ³•ï¼‰
    ///
    /// å›é€€é“¾ï¼šchat_title_model_config_id â†’ model2_config_id
    pub async fn get_chat_title_model_config(&self) -> Result<ApiConfig> {
        let assignments = self.get_model_assignments().await?;
        let model_id = assignments
            .chat_title_model_config_id
            .or(assignments.model2_config_id)
            .ok_or_else(|| AppError::configuration("æ²¡æœ‰é…ç½®å¯ç”¨çš„æ ‡é¢˜/æ ‡ç­¾ç”Ÿæˆæ¨¡å‹"))?;

        let configs = self.get_api_configs().await?;
        let config = configs
            .into_iter()
            .find(|c| c.id == model_id && !c.is_embedding && !c.is_reranker)
            .ok_or_else(|| {
                AppError::configuration(
                    "æ‰¾ä¸åˆ°æœ‰æ•ˆçš„æ ‡é¢˜/æ ‡ç­¾ç”Ÿæˆæ¨¡å‹é…ç½®ï¼ˆç¦æ­¢ä½¿ç”¨åµŒå…¥/é‡æ’åºæ¨¡å‹ï¼‰",
                )
            })?;

        Ok(config)
    }

    /// è·å– OCR æ¨¡å‹é…ç½®ï¼ˆå…¬å¼€æ–¹æ³•ï¼Œä¾›å¤šæ¨¡æ€ç´¢å¼•ç­‰é€šç”¨ OCR ä½¿ç”¨ï¼‰
    ///
    /// é»˜è®¤æŒ‰ FreeText ç­–ç•¥è¿”å›ï¼šOCR-VLMï¼ˆå¿«é€Ÿ/ä¾¿å®œï¼‰ä¼˜å…ˆäºé€šç”¨ VLMã€‚
    /// åŒç±»å†…éƒ¨ä¿æŒç”¨æˆ·è®¾ç½®çš„ priority é¡ºåºã€‚
    /// å›é€€é“¾ï¼šå·²å¯ç”¨çš„ OCR å¼•æ“ â†’ exam_sheet_ocr_model_config_id
    pub async fn get_ocr_model_config(&self) -> Result<ApiConfig> {
        use crate::ocr_adapters::OcrEngineType;

        let configs = self.get_api_configs().await?;
        let available = self.get_available_ocr_models().await;

        let mut enabled_models: Vec<&OcrModelConfig> =
            available.iter().filter(|m| m.enabled).collect();
        // FreeText ç­–ç•¥ï¼šä¸“ä¸š OCR æ¨¡å‹ä¼˜å…ˆï¼ˆå¿«é€Ÿ/ä¾¿å®œï¼‰ï¼Œé€šç”¨ VLM å…œåº•
        enabled_models.sort_by_key(|m| {
            let engine = OcrEngineType::from_str(&m.engine_type);
            (if engine.is_dedicated_ocr() { 0u8 } else { 1 }, m.priority)
        });

        // å°è¯•æŒ‰ä¼˜å…ˆçº§æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„é…ç½®
        for ocr_config in &enabled_models {
            if let Some(config) = configs.iter().find(|c| c.id == ocr_config.config_id) {
                if config.is_multimodal {
                    debug!(
                        "[OCR] ä½¿ç”¨å¼•æ“ {} å¯¹åº”çš„æ¨¡å‹é…ç½®: id={}, model={} (priority={})",
                        ocr_config.engine_type, config.id, config.model, ocr_config.priority
                    );
                    return Ok(config.clone());
                } else {
                    warn!(
                        "[OCR] å¼•æ“ {} å¯¹åº”çš„æ¨¡å‹ {} ä¸æ”¯æŒå¤šæ¨¡æ€ï¼Œè·³è¿‡",
                        ocr_config.engine_type, config.model
                    );
                }
            } else {
                warn!(
                    "[OCR] å¼•æ“ {} å¯¹åº”çš„é…ç½® ID {} ä¸å­˜åœ¨ï¼Œè·³è¿‡",
                    ocr_config.engine_type, ocr_config.config_id
                );
            }
        }

        // å›é€€ï¼šä½¿ç”¨ exam_sheet_ocr_model_config_id
        let assignments = self.get_model_assignments().await?;
        let model_id = assignments.exam_sheet_ocr_model_config_id.ok_or_else(|| {
            AppError::configuration("OCR æ¨¡å‹æœªé…ç½®ï¼Œè¯·åœ¨æ¨¡å‹åˆ†é…ä¸­æ·»åŠ  OCR å¼•æ“")
        })?;

        let config = configs
            .into_iter()
            .find(|c| c.id == model_id)
            .ok_or_else(|| {
                AppError::configuration(format!("æ‰¾ä¸åˆ° ID ä¸º {} çš„æ¨¡å‹é…ç½®", model_id))
            })?;

        if !config.is_multimodal {
            return Err(AppError::configuration(
                "å½“å‰é…ç½®çš„ OCR æ¨¡å‹æœªå¯ç”¨å¤šæ¨¡æ€èƒ½åŠ›ï¼Œè¯·é€‰æ‹©æ”¯æŒå›¾åƒè¾“å…¥çš„æ¨¡å‹ï¼ˆå¦‚ DeepSeek-OCRï¼‰",
            ));
        }

        debug!(
            "[OCR] ä½¿ç”¨é…ç½®çš„æ¨¡å‹ï¼ˆå›é€€ï¼‰: id={}, model={}",
            config.id, config.model
        );

        Ok(config)
    }

    /// æŒ‰ä¼˜å…ˆçº§è·å–æ‰€æœ‰å·²å¯ç”¨çš„ OCR å¼•æ“é…ç½®åˆ—è¡¨ï¼ˆç”¨äºç†”æ–­é‡è¯•ï¼‰
    ///
    /// æ ¹æ® `task_type` å¯¹å¼•æ“åˆ—è¡¨è¿›è¡Œåˆ†æµæ’åºï¼š
    /// - `FreeText`ï¼šOCR-VLMï¼ˆå¿«é€Ÿä¸“ä¸šæ¨¡å‹ï¼‰ä¼˜å…ˆï¼Œé€šç”¨ VLM å…œåº•
    /// - `Structured`ï¼šé€šç”¨ VLMï¼ˆGLM-4.6V ç­‰ï¼‰ä¼˜å…ˆï¼ŒOCR-VLM å…œåº•
    ///
    /// åŒç±»å¼•æ“ä¹‹é—´ä¿æŒç”¨æˆ·è®¾ç½®çš„ priority é¡ºåºã€‚
    pub async fn get_ocr_configs_by_priority(
        &self,
        task_type: crate::ocr_adapters::OcrTaskType,
    ) -> Result<Vec<(ApiConfig, crate::ocr_adapters::OcrEngineType)>> {
        use crate::ocr_adapters::{OcrAdapterFactory, OcrEngineType, OcrTaskType};

        let configs = self.get_api_configs().await?;
        let available = self.get_available_ocr_models().await;

        let mut enabled_models: Vec<&OcrModelConfig> =
            available.iter().filter(|m| m.enabled).collect();
        enabled_models.sort_by_key(|m| m.priority);

        let mut result = Vec::new();
        for ocr_config in &enabled_models {
            if let Some(config) = configs.iter().find(|c| c.id == ocr_config.config_id) {
                if !config.is_multimodal {
                    continue;
                }
                let engine = OcrEngineType::from_str(&ocr_config.engine_type);
                let effective_engine =
                    if OcrAdapterFactory::validate_model_for_engine(&config.model, engine) {
                        engine
                    } else {
                        OcrAdapterFactory::infer_engine_from_model(&config.model)
                    };
                result.push((config.clone(), effective_engine));
            }
        }

        if result.is_empty() {
            if let Ok(config) = self.get_ocr_model_config().await {
                let engine = OcrAdapterFactory::infer_engine_from_model(&config.model);
                result.push((config, engine));
            }
        }

        if result.is_empty() {
            return Err(AppError::configuration(
                "æ²¡æœ‰å¯ç”¨çš„ OCR å¼•æ“é…ç½®ï¼Œè¯·åœ¨è®¾ç½®ä¸­æ·»åŠ  OCR å¼•æ“",
            ));
        }

        // æŒ‰ä»»åŠ¡ç±»å‹åˆ†æµï¼šstable partition ä¿æŒåŒç±»å†…éƒ¨çš„ priority é¡ºåº
        match task_type {
            OcrTaskType::FreeText => {
                // ä¸“ä¸š OCR æ¨¡å‹åœ¨å‰ï¼ˆå¿«ã€ä¾¿å®œï¼‰ï¼Œé€šç”¨ VLM åœ¨å
                result.sort_by_key(|(_, engine)| if engine.is_dedicated_ocr() { 0 } else { 1 });
            }
            OcrTaskType::Structured => {
                // é€šç”¨ VLM åœ¨å‰ï¼ˆGLM-4.6V ç­‰ï¼Œå¤æ‚å¸ƒå±€ç†è§£èƒ½åŠ›å¼ºï¼‰ï¼Œä¸“ä¸š OCR åœ¨å
                result.sort_by_key(|(_, engine)| if engine.is_dedicated_ocr() { 1 } else { 0 });
            }
        }

        debug!(
            "[OCR] å¼•æ“ä¼˜å…ˆçº§ï¼ˆ{:?}ï¼‰: {}",
            task_type,
            result
                .iter()
                .enumerate()
                .map(|(i, (c, e))| format!("#{} {}({})", i, e.display_name(), c.model))
                .collect::<Vec<_>>()
                .join(" â†’ ")
        );

        Ok(result)
    }

    /// è·å–æ‰€æœ‰å·²é…ç½®çš„ OCR æ¨¡å‹åˆ—è¡¨
    ///
    /// åŒ…å«è‡ªåŠ¨è¿ç§»é€»è¾‘ï¼š
    /// 1. å°†æ—§ç‰ˆæœ¬ PaddleOCR-VL æ¨¡å‹åç§°è‡ªåŠ¨æ›´æ–°ä¸º 1.5 ç‰ˆæœ¬
    /// 2. ä»æ—§ ocr.engine_type å•é€‰è¿ç§»åˆ°æ–°ä¼˜å…ˆçº§åˆ—è¡¨
    pub async fn get_available_ocr_models(&self) -> Vec<OcrModelConfig> {
        if let Ok(Some(json)) = self.db.get_setting("ocr.available_models") {
            if let Ok(mut models) = serde_json::from_str::<Vec<OcrModelConfig>>(&json) {
                let mut needs_save = crate::cmd::ocr::migrate_paddle_ocr_models(&mut models);

                // GLM-4.1V â†’ 4.6V è¿ç§»ï¼šåŒæ—¶æ›´æ–°å…³è”çš„ ApiConfig.model
                let glm_migrate_ids: Vec<String> = models
                    .iter()
                    .filter(|m| {
                        m.engine_type == "glm4v_ocr"
                            && m.model.to_lowercase().contains("glm-4.1v")
                    })
                    .map(|m| m.config_id.clone())
                    .collect();

                if crate::cmd::ocr::migrate_glm_ocr_models(&mut models) {
                    needs_save = true;
                    // åŒæ­¥æ›´æ–° ApiConfig ä¸­çš„ model å­—æ®µï¼Œç¡®ä¿å®é™… API è°ƒç”¨ä¹Ÿä½¿ç”¨æ–°æ¨¡å‹
                    if !glm_migrate_ids.is_empty() {
                        if let Ok(mut api_configs) = self.get_api_configs().await {
                            let mut api_changed = false;
                            for cfg in api_configs.iter_mut() {
                                if glm_migrate_ids.contains(&cfg.id)
                                    && cfg.model.to_lowercase().contains("glm-4.1v")
                                {
                                    info!(
                                        "[OCR] åŒæ­¥æ›´æ–° ApiConfig model: {} â†’ zai-org/GLM-4.6V (id={})",
                                        cfg.model, cfg.id
                                    );
                                    cfg.model = "zai-org/GLM-4.6V".to_string();
                                    cfg.name = cfg.name.replace("GLM-4.1V", "GLM-4.6V")
                                        .replace("4.1V", "4.6V");
                                    api_changed = true;
                                }
                            }
                            if api_changed {
                                let _ = self.save_api_configurations(&api_configs).await;
                            }
                        }
                    }
                }

                // è¿ç§»ï¼šå¦‚æœæ‰€æœ‰ priority éƒ½æ˜¯ 0 ä¸”å­˜åœ¨æ—§ ocr.engine_type è®¾ç½®ï¼Œ
                // åˆ™æ ¹æ®æ—§å•é€‰è®¾ç½®è°ƒæ•´ä¼˜å…ˆçº§
                if models.len() > 1 && models.iter().all(|m| m.priority == 0) {
                    if let Ok(Some(old_engine)) = self.db.get_setting("ocr.engine_type") {
                        for (i, model) in models.iter_mut().enumerate() {
                            if model.engine_type == old_engine {
                                model.priority = 0; // æ—§é€‰ä¸­çš„æ’ç¬¬ä¸€
                            } else {
                                model.priority = (i as u32) + 1;
                            }
                        }
                        // é‡æ–°æŒ‰ priority æ’åºç¡®ä¿ä¸€è‡´
                        models.sort_by_key(|m| m.priority);
                        // é‡æ–°ç¼–å·
                        for (i, model) in models.iter_mut().enumerate() {
                            model.priority = i as u32;
                        }
                        needs_save = true;
                        info!(
                            "[OCR] å·²ä»æ—§ ocr.engine_type='{}' è¿ç§»åˆ°ä¼˜å…ˆçº§åˆ—è¡¨",
                            old_engine
                        );
                    }
                }

                if needs_save {
                    if let Ok(updated_json) = serde_json::to_string(&models) {
                        let _ = self.db.save_setting("ocr.available_models", &updated_json);
                    }
                }
                return models;
            }
        }
        Vec::new()
    }

    /// ä½¿ç”¨æŒ‡å®šå¼•æ“æµ‹è¯• OCR
    ///
    /// ç”¨äºå¯¹æ¯”ä¸åŒ OCR å¼•æ“çš„é€Ÿåº¦å’Œè´¨é‡
    pub async fn test_ocr_with_engine(
        &self,
        image_path: String,
        engine_type: crate::ocr_adapters::OcrEngineType,
        config_id: Option<&str>,
    ) -> Result<(String, Vec<crate::ocr_adapters::OcrRegion>)> {
        use crate::ocr_adapters::{OcrAdapterFactory, OcrMode, OcrRegion};
        use crate::providers::ProviderAdapter;
        use serde_json::json;

        // è·å–æŒ‡å®šå¼•æ“çš„é€‚é…å™¨
        let adapter = OcrAdapterFactory::create(engine_type);
        let engine_name = adapter.display_name();
        let ocr_mode = OcrMode::Grounding;

        // ä¼˜å…ˆé€šè¿‡ config_id ç²¾ç¡®æŸ¥æ‰¾ï¼Œå›é€€åˆ° engine_type æŸ¥æ‰¾
        let config = if let Some(cid) = config_id {
            let configs = self.get_api_configs().await?;
            configs
                .into_iter()
                .find(|c| c.id == cid)
                .ok_or_else(|| AppError::configuration(format!("æ‰¾ä¸åˆ°é…ç½® ID: {}", cid)))?
        } else {
            self.get_ocr_model_config_for_engine(engine_type).await?
        };

        debug!(
            "[OCR Test] ä½¿ç”¨å¼•æ“ {} æµ‹è¯•ï¼Œæ¨¡å‹: {}",
            engine_name, config.model
        );

        // å‡†å¤‡å›¾ç‰‡æ•°æ®
        let mime = Self::infer_image_mime(&image_path);
        let (data_url, _) = self
            .prepare_segmentation_image_data(&image_path, mime)
            .await?;

        // æ„å»ºè¯·æ±‚
        let prompt_text = adapter.build_prompt(ocr_mode);
        let messages = vec![json!({
            "role": "user",
            "content": [
                { "type": "image_url", "image_url": { "url": data_url, "detail": if adapter.requires_high_detail() { "high" } else { "low" } } },
                { "type": "text", "text": prompt_text }
            ]
        })];

        let max_tokens = effective_max_tokens(config.max_output_tokens, config.max_tokens_limit)
            .min(adapter.recommended_max_tokens(ocr_mode))
            .max(2048)
            .min(8000);

        // æ„å»ºåŸºç¡€è¯·æ±‚ä½“
        let mut request_body = json!({
            "model": config.model,
            "messages": messages,
            "temperature": adapter.recommended_temperature(),
            "max_tokens": max_tokens,
            "stream": false,
        });

        if let Some(extra) = adapter.get_extra_request_params() {
            if let Some(obj) = request_body.as_object_mut() {
                if let Some(extra_obj) = extra.as_object() {
                    for (k, v) in extra_obj {
                        obj.insert(k.to_string(), v.clone());
                    }
                } else {
                    obj.insert("extra_params".to_string(), extra);
                }
            }
        }

        // å¦‚æœé€‚é…å™¨æ¨èè®¾ç½® repetition_penaltyï¼Œåˆ™æ·»åŠ åˆ°è¯·æ±‚ä¸­
        // è¿™å¯¹ PaddleOCR-VL ç­‰æ¨¡å‹å¾ˆé‡è¦ï¼Œå¯ä»¥é¿å…é‡å¤è¾“å‡ºé—®é¢˜
        if let Some(repetition_penalty) = adapter.recommended_repetition_penalty() {
            if let Some(obj) = request_body.as_object_mut() {
                obj.insert("repetition_penalty".to_string(), json!(repetition_penalty));
            }
            debug!(
                "[OCR Test] è®¾ç½® repetition_penalty = {} (é¿å…é‡å¤è¾“å‡º)",
                repetition_penalty
            );
        }

        // é€‰æ‹©é€‚é…å™¨
        let provider_adapter: Box<dyn ProviderAdapter> = match config.model_adapter.as_str() {
            "google" | "gemini" => Box::new(crate::providers::GeminiAdapter::new()),
            "anthropic" | "claude" => Box::new(crate::providers::AnthropicAdapter::new()),
            _ => Box::new(crate::providers::OpenAIAdapter),
        };

        let preq = provider_adapter
            .build_request(
                &config.base_url,
                &config.api_key,
                &config.model,
                &request_body,
            )
            .map_err(|e| AppError::llm(format!("{} è¯·æ±‚æ„å»ºå¤±è´¥: {}", engine_name, e)))?;

        model2_pipeline::log_llm_request_audit(
            "OCR_ENGINE_TEST",
            &preq.url,
            &config.model,
            &request_body,
        );

        // å‘é€è¯·æ±‚
        let client = reqwest::Client::builder()
            .timeout(std::time::Duration::from_secs(300))
            .build()
            .map_err(|e| AppError::network(format!("åˆ›å»º HTTP å®¢æˆ·ç«¯å¤±è´¥: {}", e)))?;

        let mut header_map = reqwest::header::HeaderMap::new();
        for (k, v) in preq.headers.iter() {
            if let (Ok(name), Ok(val)) = (
                reqwest::header::HeaderName::from_bytes(k.as_bytes()),
                reqwest::header::HeaderValue::from_str(v),
            ) {
                header_map.insert(name, val);
            }
        }

        let response = client
            .post(&preq.url)
            .headers(header_map)
            .json(&preq.body)
            .send()
            .await
            .map_err(|e| AppError::network(format!("{} è¯·æ±‚å¤±è´¥: {}", engine_name, e)))?;

        let status = response.status();
        if !status.is_success() {
            let error_text = response.text().await.unwrap_or_default();
            return Err(AppError::llm(format!(
                "{} API è¿”å›é”™è¯¯ ({}): {}",
                engine_name, status, error_text
            )));
        }

        let response_json: serde_json::Value = response
            .json()
            .await
            .map_err(|e| AppError::llm(format!("è§£æ {} å“åº”å¤±è´¥: {}", engine_name, e)))?;

        // æå–å“åº”æ–‡æœ¬
        let content = response_json
            .pointer("/choices/0/message/content")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();

        // è·å–å›¾ç‰‡å°ºå¯¸ï¼ˆç”¨äºåæ ‡è½¬æ¢ï¼‰
        let (image_width, image_height) =
            image::image_dimensions(&image_path).unwrap_or((1000, 1000));

        // ä½¿ç”¨é€‚é…å™¨è§£æå“åº”
        let parse_result = adapter.parse_response(
            &content,
            image_width,
            image_height,
            0, // page_index
            &image_path,
            OcrMode::Grounding,
        );

        // æå–åŒºåŸŸåˆ—è¡¨
        let regions = match parse_result {
            Ok(page_result) => page_result.regions,
            Err(_) => {
                // è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬ä½œä¸ºå•ä¸ªåŒºåŸŸ
                vec![OcrRegion {
                    label: "text".to_string(),
                    text: content.clone(),
                    bbox_normalized: None,
                    bbox_pixels: None,
                    confidence: None,
                    raw_output: Some(content.clone()),
                }]
            }
        };

        // å¦‚æœæ²¡æœ‰è§£æå‡ºåŒºåŸŸï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«å…¨éƒ¨æ–‡æœ¬çš„é»˜è®¤åŒºåŸŸ
        let final_regions = if regions.is_empty() {
            vec![OcrRegion {
                label: "text".to_string(),
                text: content.clone(),
                bbox_normalized: None,
                bbox_pixels: None,
                confidence: None,
                raw_output: Some(content.clone()),
            }]
        } else {
            regions
        };

        // åˆå¹¶æ‰€æœ‰åŒºåŸŸçš„æ–‡æœ¬
        let full_text = final_regions
            .iter()
            .map(|r| r.text.as_str())
            .collect::<Vec<_>>()
            .join("\n");

        Ok((full_text, final_regions))
    }

    /// è·å–æŒ‡å®šå¼•æ“ç±»å‹å¯¹åº”çš„æ¨¡å‹é…ç½®
    async fn get_ocr_model_config_for_engine(
        &self,
        engine_type: crate::ocr_adapters::OcrEngineType,
    ) -> Result<ApiConfig> {
        let configs = self.get_api_configs().await?;

        // å°è¯•ä» ocr.available_models ä¸­æŸ¥æ‰¾å¯¹åº”å¼•æ“çš„é…ç½® ID
        if let Ok(Some(available_models_json)) = self.db.get_setting("ocr.available_models") {
            if let Ok(available_models) =
                serde_json::from_str::<Vec<OcrModelConfig>>(&available_models_json)
            {
                if let Some(ocr_config) = available_models
                    .iter()
                    .find(|m| m.engine_type == engine_type.as_str())
                {
                    if let Some(config) = configs.iter().find(|c| c.id == ocr_config.config_id) {
                        return Ok(config.clone());
                    }
                }
            }
        }

        // å›é€€ï¼šå°è¯•æ ¹æ®æ¨¡å‹åç§°åŒ¹é…
        let recommended_model = engine_type.recommended_model();
        if let Some(config) = configs
            .iter()
            .find(|c| c.model.contains(recommended_model) || recommended_model.contains(&c.model))
        {
            return Ok(config.clone());
        }

        // æœ€ç»ˆå›é€€ï¼šä½¿ç”¨é»˜è®¤ OCR æ¨¡å‹é…ç½®
        self.get_ocr_model_config().await
    }

    /// OCR/é¢˜ç›®é›†ä»»åŠ¡æ˜¯å¦å¯ç”¨ VLM æ¨ç†ï¼ˆthinkingï¼‰
    ///
    /// é»˜è®¤å…³é—­ï¼šOCR å’Œç»“æ„åŒ–ä»»åŠ¡ä¸éœ€è¦æ·±åº¦æ¨ç†ï¼Œå…³é—­å¯æ˜¾è‘—é™ä½å»¶è¿Ÿå’Œæˆæœ¬ã€‚
    pub fn is_ocr_thinking_enabled(&self) -> bool {
        self.db
            .get_setting("ocr.enable_thinking")
            .ok()
            .flatten()
            .map(|v| v.to_lowercase() == "true")
            .unwrap_or(false)
    }

    /// è·å–å½“å‰é…ç½®çš„ OCR å¼•æ“ç±»å‹
    ///
    /// é»˜è®¤æŒ‰ FreeText ç­–ç•¥ï¼šOCR-VLM å¼•æ“ä¼˜å…ˆäºé€šç”¨ VLMã€‚
    /// å›é€€åˆ° `ocr.engine_type` è®¾ç½®ï¼Œæœ€ç»ˆé»˜è®¤ PaddleOCR-VL-1.5ã€‚
    pub async fn get_ocr_engine_type(&self) -> crate::ocr_adapters::OcrEngineType {
        use crate::ocr_adapters::OcrEngineType;

        let available = self.get_available_ocr_models().await;
        let mut enabled: Vec<&OcrModelConfig> = available.iter().filter(|m| m.enabled).collect();
        // FreeText ç­–ç•¥ï¼šä¸“ä¸š OCR å¼•æ“ä¼˜å…ˆ
        enabled.sort_by_key(|m| {
            let engine = OcrEngineType::from_str(&m.engine_type);
            (if engine.is_dedicated_ocr() { 0u8 } else { 1 }, m.priority)
        });

        if let Some(first) = enabled.first() {
            return OcrEngineType::from_str(&first.engine_type);
        }

        // å›é€€åˆ° legacy è®¾ç½®
        let engine_str = self
            .db
            .get_setting("ocr.engine_type")
            .ok()
            .flatten()
            .unwrap_or_else(|| "paddle_ocr_vl".to_string());

        OcrEngineType::from_str(&engine_str)
    }

    /// è·å–å½“å‰é…ç½®çš„ OCR é€‚é…å™¨
    ///
    /// æ ¹æ®æ•°æ®åº“é…ç½®è¿”å›å¯¹åº”çš„ OCR é€‚é…å™¨å®ä¾‹
    pub async fn get_ocr_adapter(&self) -> std::sync::Arc<dyn crate::ocr_adapters::OcrAdapter> {
        use crate::ocr_adapters::OcrAdapterFactory;

        let engine_type = self.get_ocr_engine_type().await;
        OcrAdapterFactory::create(engine_type)
    }

    /// S4/S7 fix: è·å– OCR æ¨¡å‹é…ç½®åŠå…¶æœ‰æ•ˆå¼•æ“ç±»å‹
    ///
    /// ä¼˜å…ˆä» available_models ä¸­æŸ¥æ‰¾åŒ¹é…çš„å¼•æ“ç±»å‹ï¼Œ
    /// æ‰¾ä¸åˆ°æ—¶æ ¹æ®å®é™…æ¨¡å‹æ¨æ–­å¼•æ“ç±»å‹ï¼Œ
    /// ç¡®ä¿ adapter/prompt/parser ä¸‰è€…å§‹ç»ˆä¸å®é™…æ¨¡å‹åŒ¹é…ã€‚
    pub async fn get_ocr_config_with_effective_engine(
        &self,
    ) -> Result<(ApiConfig, crate::ocr_adapters::OcrEngineType)> {
        use crate::ocr_adapters::{OcrAdapterFactory, OcrEngineType};

        let config = self.get_ocr_model_config().await?;

        // ä» available_models ä¸­æŸ¥æ‰¾è¯¥ config_id å¯¹åº”çš„å¼•æ“ç±»å‹
        let available = self.get_available_ocr_models().await;
        let effective_engine =
            if let Some(ocr_model) = available.iter().find(|m| m.config_id == config.id) {
                let declared = OcrEngineType::from_str(&ocr_model.engine_type);
                // éªŒè¯å£°æ˜çš„å¼•æ“ç±»å‹æ˜¯å¦åŒ¹é…å®é™…æ¨¡å‹
                if OcrAdapterFactory::validate_model_for_engine(&config.model, declared) {
                    declared
                } else {
                    OcrAdapterFactory::infer_engine_from_model(&config.model)
                }
            } else {
                // å›é€€é…ç½®ï¼Œæ ¹æ®æ¨¡å‹æ¨æ–­
                OcrAdapterFactory::infer_engine_from_model(&config.model)
            };

        debug!(
            "[OCR] effective engine={}, model={}",
            effective_engine.as_str(),
            config.model
        );

        Ok((config, effective_engine))
    }

    // è·å– Anki åˆ¶å¡æ¨¡å‹é…ç½®
    async fn get_anki_model_config(&self) -> Result<ApiConfig> {
        let assignments = self.get_model_assignments().await?;
        let anki_model_id = assignments
            .anki_card_model_config_id
            .ok_or_else(|| AppError::configuration("Ankiåˆ¶å¡æ¨¡å‹æœªé…ç½®"))?;

        let configs = self.get_api_configs().await?;
        // æ³¨æ„ï¼šå·²åˆ†é…çš„æ¨¡å‹å³ä½¿ enabled=false ä¹Ÿå…è®¸ä½¿ç”¨
        let config = configs
            .into_iter()
            .find(|c| c.id == anki_model_id)
            .ok_or_else(|| AppError::configuration("æ‰¾ä¸åˆ°æœ‰æ•ˆçš„Ankiåˆ¶å¡æ¨¡å‹é…ç½®"))?;

        debug!(
            "æ‰¾åˆ° Anki åˆ¶å¡æ¨¡å‹é…ç½®: æ¨¡å‹={}, APIåœ°å€={}",
            config.model, config.base_url
        );
        Ok(config)
    }

    /// ç»Ÿä¸€æ¨¡å‹é€‰æ‹©å‡½æ•°
    ///
    /// å‚æ•°ï¼š
    /// - task: ä»»åŠ¡ç±»å‹ ("default"|"review"|"chat_title"|"tag_generation")
    /// - override_id: å¯é€‰çš„è¦†ç›–æ¨¡å‹ID
    /// - temperature: å¯é€‰çš„æ¸©åº¦è¦†ç›–
    /// - top_p: å¯é€‰çš„ Top-P è¦†ç›–
    /// - frequency_penalty: å¯é€‰çš„é¢‘ç‡æƒ©ç½šè¦†ç›–
    /// - presence_penalty: å¯é€‰çš„å­˜åœ¨æƒ©ç½šè¦†ç›–
    /// - max_output_tokens: å¯é€‰çš„æœ€å¤§è¾“å‡º tokens è¦†ç›–
    ///
    /// è¿”å›ï¼š(ApiConfig, enable_cot)
    pub async fn select_model_for(
        &self,
        task: &str,
        override_id: Option<String>,
        temperature: Option<f32>,
        top_p: Option<f32>,
        frequency_penalty: Option<f32>,
        presence_penalty: Option<f32>,
        max_output_tokens: Option<u32>,
    ) -> Result<(ApiConfig, bool)> {
        // å¦‚æœæœ‰è¦†ç›–IDï¼Œä½¿ç”¨è¦†ç›–é…ç½®
        // æ³¨æ„ï¼šè¦†ç›–æ¨¡å‹å³ä½¿ enabled=false ä¹Ÿå…è®¸ä½¿ç”¨ï¼ˆç”¨äºå†å²æ¶ˆæ¯é‡è¯•ç­‰åœºæ™¯ï¼‰
        if let Some(ref override_id) = override_id {
            let configs = self.get_api_configs().await?;
            let mut config = configs
                .into_iter()
                .find(|c| c.id == *override_id)
                .ok_or_else(|| {
                    AppError::configuration(format!("æ‰¾ä¸åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®: {}", override_id))
                })?;

            // åº”ç”¨å‚æ•°è¦†ç›–
            if let Some(temp) = temperature {
                config.temperature = temp;
            }
            if let Some(max_tokens) = max_output_tokens {
                config.max_output_tokens = max_tokens;
            }
            config.top_p_override = top_p;
            config.frequency_penalty_override = frequency_penalty;
            config.presence_penalty_override = presence_penalty;

            let enable_cot = config.is_reasoning;
            return Ok((config, enable_cot));
        }

        // æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ¨¡å‹
        let assignments = self.get_model_assignments().await?;
        let configs = self.get_api_configs().await?;

        let (model_id, enable_cot) = match task {
            "default" => {
                let model_id = assignments
                    .model2_config_id
                    .ok_or_else(|| AppError::configuration("å¯¹è¯æ¨¡å‹æœªé…ç½®"))?;
                (model_id, true) // é»˜è®¤å¯ç”¨CoT
            }
            "chat_title" | "tag_generation" => {
                let model_id = assignments
                    .chat_title_model_config_id
                    .or(assignments.model2_config_id)
                    .ok_or_else(|| AppError::configuration("æ²¡æœ‰é…ç½®å¯ç”¨çš„æ ‡é¢˜/æ ‡ç­¾ç”Ÿæˆæ¨¡å‹"))?;
                (model_id, false)
            }
            "review" => {
                let model_id = assignments
                    .review_analysis_model_config_id
                    .ok_or_else(|| AppError::configuration("æœªé…ç½®å›é¡¾åˆ†ææ¨¡å‹"))?;
                (model_id, true) // å›é¡¾åˆ†æé€šå¸¸éœ€è¦CoT
            }
            _ => {
                return Err(AppError::configuration(format!(
                    "ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {}",
                    task
                )))
            }
        };

        // æ³¨æ„ï¼šå·²åˆ†é…çš„æ¨¡å‹å³ä½¿ enabled=false ä¹Ÿå…è®¸ä½¿ç”¨
        // enabled ä»…å½±å“æ¨¡å‹é€‰æ‹©å™¨ä¸­çš„æ˜¾ç¤ºï¼Œä¸é˜»æ­¢å·²åˆ†é…æ¨¡å‹çš„è°ƒç”¨
        let mut config = configs
            .into_iter()
            .find(|c| c.id == model_id)
            .ok_or_else(|| {
                AppError::configuration(format!("æ‰¾ä¸åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®: {}", model_id))
            })?;

        // åº”ç”¨å‚æ•°è¦†ç›–
        if let Some(temp) = temperature {
            config.temperature = temp;
        }
        if let Some(max_tokens) = max_output_tokens {
            config.max_output_tokens = max_tokens;
        }
        config.top_p_override = top_p;
        config.frequency_penalty_override = frequency_penalty;
        config.presence_penalty_override = presence_penalty;

        // CoTç­–ç•¥ï¼šé»˜è®¤é‡‡ç”¨config.is_reasoningï¼Œä½†å¯ä»¥è¢«ä»»åŠ¡ç‰¹å®šé€»è¾‘è¦†ç›–
        let final_enable_cot = config.is_reasoning && enable_cot;

        Ok((config, final_enable_cot))
    }

    // è·å–æ¨¡å‹åˆ†é…é…ç½®
    pub async fn get_model_assignments(&self) -> Result<ModelAssignments> {
        let assignments_str = self.db.get_setting("model_assignments")
            .map_err(|e| AppError::database(format!("è·å–æ¨¡å‹åˆ†é…é…ç½®å¤±è´¥: {}", e)))?
            .unwrap_or_else(|| r#"{"model2_config_id": null, "review_analysis_model_config_id": null, "anki_card_model_config_id": null, "qbank_ai_grading_model_config_id": null}"#.to_string());

        let assignments: ModelAssignments = serde_json::from_str(&assignments_str)
            .map_err(|e| AppError::configuration(format!("è§£ææ¨¡å‹åˆ†é…é…ç½®å¤±è´¥: {}", e)))?;

        Ok(assignments)
    }

    // ä¿å­˜æ¨¡å‹åˆ†é…é…ç½®
    pub async fn save_model_assignments(&self, assignments: &ModelAssignments) -> Result<()> {
        let assignments_str = serde_json::to_string(assignments)
            .map_err(|e| AppError::configuration(format!("åºåˆ—åŒ–æ¨¡å‹åˆ†é…é…ç½®å¤±è´¥: {}", e)))?;

        self.db
            .save_setting("model_assignments", &assignments_str)
            .map_err(|e| AppError::database(format!("ä¿å­˜æ¨¡å‹åˆ†é…é…ç½®å¤±è´¥: {}", e)))?;

        Ok(())
    }

    // ä¿å­˜APIé…ç½®ï¼ˆå…¼å®¹æ—§è°ƒç”¨ï¼Œè‡ªåŠ¨æ˜ å°„åˆ°ä¾›åº”å•†/æ¨¡å‹ï¼‰
    pub async fn save_api_configurations(&self, configs: &[ApiConfig]) -> Result<()> {
        self.bootstrap_vendor_model_config().await?;

        let mut plain_configs: Vec<ApiConfig> = configs
            .iter()
            .filter(|cfg| !cfg.is_builtin)
            .cloned()
            .collect();

        for cfg in &mut plain_configs {
            cfg.api_key = self.decrypt_api_key_if_needed(&cfg.api_key)?;
        }

        let (mut vendors, mut profiles) = self
            .flatten_api_configs_to_vendor_profiles(&plain_configs)
            .await?;

        vendors.retain(|v| !v.is_builtin);
        profiles.retain(|p| !p.is_builtin);

        self.save_vendor_model_configs(&vendors, &profiles).await
    }

    // åŠ å¯†APIå¯†é’¥
    fn encrypt_api_key(&self, api_key: &str) -> Result<String> {
        // å¦‚æœå·²ç»æ˜¯åŠ å¯†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if CryptoService::is_encrypted_format(api_key) {
            return Ok(api_key.to_string());
        }

        let encrypted_data = self
            .crypto_service
            .encrypt_api_key(api_key)
            .map_err(|e| AppError::configuration(format!("åŠ å¯†APIå¯†é’¥å¤±è´¥: {}", e)))?;

        serde_json::to_string(&encrypted_data)
            .map_err(|e| AppError::configuration(format!("åºåˆ—åŒ–åŠ å¯†æ•°æ®å¤±è´¥: {}", e)))
    }

    pub(crate) fn decrypt_api_key_if_needed(&self, api_key: &str) -> Result<String> {
        // æ£€æŸ¥æ˜¯å¦ä¸ºåŠ å¯†æ ¼å¼
        if CryptoService::is_encrypted_format(api_key) {
            let encrypted_data: EncryptedData = serde_json::from_str(api_key)
                .map_err(|e| AppError::configuration(format!("è§£æåŠ å¯†æ•°æ®å¤±è´¥: {}", e)))?;

            self.crypto_service
                .decrypt_api_key(&encrypted_data)
                .map_err(|e| AppError::configuration(format!("è§£å¯†APIå¯†é’¥å¤±è´¥: {}", e)))
        } else {
            // æ˜æ–‡æ ¼å¼ï¼Œè¿ç§»åˆ°åŠ å¯†æ ¼å¼ï¼ˆé™é»˜å¤„ç†ï¼Œé¿å…æ—¥å¿—å™ªéŸ³ï¼‰
            Ok(api_key.to_string())
        }
    }

    /// å…¬å¼€çš„ API Key è§£å¯†æ–¹æ³•ï¼ˆä¾›ç¿»è¯‘æ¨¡å—ç­‰ä½¿ç”¨ï¼‰
    pub fn decrypt_api_key(&self, api_key: &str) -> Result<String> {
        self.decrypt_api_key_if_needed(api_key)
    }
}
// ==================== Global singleton helper ====================
use std::sync::OnceLock;
// no extra traits needed for listen/unlisten

impl LLMManager {
    /// Get global singleton (constructed lazily with default Database & FileManager).
    /// This prevents multiple heavy clients and allows background jobs reuse.
    pub async fn global() -> anyhow::Result<Arc<LLMManager>> {
        static INSTANCE: OnceLock<Arc<LLMManager>> = OnceLock::new();

        if let Some(mgr) = INSTANCE.get() {
            return Ok(mgr.clone());
        }

        // æ„é€ å…¨å±€å®ä¾‹ç›®å‰ä¾èµ–è¾ƒå¤šç»„ä»¶ï¼Œè‹¥æœªå‡†å¤‡å¥½ç›´æ¥è¿”å›é”™è¯¯
        Err(anyhow::anyhow!(
            "LLMManager::global is not yet implemented in this build"
        ))
    }

    /// æ„å»ºå·¥å…·åˆ—è¡¨ï¼ŒåŒ…å«æœ¬åœ°å·¥å…·å’Œ MCP å·¥å…·
    async fn build_tools_with_mcp(&self, window: &Window) -> Value {
        // æœ¬åœ°å·¥å…·å®šä¹‰ï¼ˆæŒ‰å¼€å…³åŠ¨æ€å¹¿å‘Šï¼‰
        let mut tools_array = Vec::new();

        // æ¡ä»¶å¹¿å‘Š web_searchï¼ˆä»…ç”±æ¶ˆæ¯çº§é€‰æ‹©æ§åˆ¶ï¼‰
        let selected_engines_list = self
            .db
            .get_setting("session.selected_search_engines")
            .ok()
            .flatten()
            .unwrap_or_default();
        let has_selected_engines = !selected_engines_list.trim().is_empty();

        // è°ƒè¯•ä¿¡æ¯ï¼šæœç´¢å¼•æ“é…ç½®çŠ¶æ€
        debug!(
            "[æœç´¢å¼•æ“] é…ç½®: {:?}, å·¥å…·å¯ç”¨: {}",
            selected_engines_list, has_selected_engines
        );

        if has_selected_engines {
            // è§£æé€‰ä¸­çš„æœç´¢å¼•æ“åˆ—è¡¨
            let selected_engines: Vec<String> = selected_engines_list
                .split(',')
                .map(|s| s.trim().to_string())
                .filter(|s| !s.is_empty())
                .collect();

            // æ„å»º web_search å·¥å…·å‚æ•°ï¼ŒåŠ¨æ€æ³¨å…¥å¼•æ“æšä¸¾çº¦æŸ
            let mut properties = json!({
                "query": { "type": "string", "description": "The web search query" },
                "top_k": { "type": "integer", "description": "Max results to return", "default": 5 },
                "site": { "type": "string", "description": "Optional site restriction (e.g., example.com)" },
                "time_range": { "type": "string", "description": "Optional time range: 1d|7d|30d" }
            });

            // å¦‚æœæœ‰å¤šä¸ªå¼•æ“é€‰ä¸­ï¼Œæ·»åŠ engineå‚æ•°çš„æšä¸¾çº¦æŸ
            if selected_engines.len() > 1 {
                properties["engine"] = json!({
                    "type": "string",
                    "enum": selected_engines,
                    "description": format!("Search engine to use. Available: {}", selected_engines.join(", "))
                });
            } else if selected_engines.len() == 1 {
                // åªæœ‰ä¸€ä¸ªå¼•æ“æ—¶ï¼Œä¸æš´éœ²engineå‚æ•°ï¼Œå·¥å…·å†…éƒ¨è‡ªåŠ¨ä½¿ç”¨
                debug!(
                    "Single search engine selected: {}, engine parameter hidden",
                    selected_engines[0]
                );
            }

            tools_array.push(json!({
                "type": "function",
                "function": {
                    "name": "web_search",
                    "description": "Search the INTERNET/WEB for current information, news, people, events, or any information not available in local knowledge base. Use this when users explicitly ask for web search or for real-time/current information.",
                    "parameters": {
                        "type": "object",
                        "properties": properties,
                        "required": ["query"]
                    }
                }
            }));

            debug!(
                "[å·¥å…·] web_searchå·¥å…·å·²æˆåŠŸæ·»åŠ åˆ°å·¥å…·åˆ—è¡¨ï¼Œé€‰ä¸­å¼•æ“: {:?}",
                selected_engines
            );
        } else {
            debug!("[å·¥å…·] web_searchå·¥å…·æœªæ·»åŠ ï¼šæ²¡æœ‰é€‰ä¸­çš„æœç´¢å¼•æ“");
        }

        // ===== MCP å·¥å…·å¹¿å‘Šï¼ˆç»ç”±å‰ç«¯SDKæ¡¥æ¥ï¼‰ =====
        let cache_ttl_ms: u64 = self
            .db
            .get_setting("mcp.performance.cache_ttl_ms")
            .ok()
            .flatten()
            .and_then(|v| v.parse::<u64>().ok())
            .unwrap_or(300_000);
        let cache_ttl = Duration::from_millis(cache_ttl_ms);
        let namespace_prefix = self
            .db
            .get_setting("mcp.tools.namespace_prefix")
            .ok()
            .flatten()
            .unwrap_or_default();
        let advertise_all = self
            .db
            .get_setting("mcp.tools.advertise_all_tools")
            .ok()
            .flatten()
            .map(|v| v.to_lowercase())
            .map(|v| v != "0" && v != "false")
            .unwrap_or(false);
        let whitelist: Vec<String> = self
            .db
            .get_setting("mcp.tools.whitelist")
            .ok()
            .flatten()
            .map(|s| {
                s.split(',')
                    .map(|x| x.trim().to_string())
                    .filter(|x| !x.is_empty())
                    .collect()
            })
            .unwrap_or_else(|| Vec::new());
        let blacklist: Vec<String> = self
            .db
            .get_setting("mcp.tools.blacklist")
            .ok()
            .flatten()
            .map(|s| {
                s.split(',')
                    .map(|x| x.trim().to_string())
                    .filter(|x| !x.is_empty())
                    .collect()
            })
            .unwrap_or_else(|| Vec::new());
        let selected: Vec<String> = self
            .db
            .get_setting("session.selected_mcp_tools")
            .ok()
            .flatten()
            .map(|s| {
                s.split(',')
                    .map(|x| x.trim().to_string())
                    .filter(|x| !x.is_empty())
                    .collect()
            })
            .unwrap_or_else(|| Vec::new());

        let mcp_tools = self.get_frontend_mcp_tools_cached(window, cache_ttl).await;
        let mut included_count = 0usize;
        for t in mcp_tools {
            let name = t.name.clone();
            // é€‰æ‹©/ç™½é»‘åå•ç­–ç•¥
            let mut allowed = if !selected.is_empty() {
                selected.iter().any(|s| s == &name)
            } else if advertise_all {
                true
            } else if !whitelist.is_empty() {
                whitelist.iter().any(|s| s == &name)
            } else {
                // é»˜è®¤ä¸å¹¿å‘Šï¼Œé™¤éè¢«é€‰æ‹©æˆ–ç™½åå•å¼€å¯
                false
            };
            if !blacklist.is_empty() && blacklist.iter().any(|s| s == &name) {
                allowed = false;
            }
            if !allowed {
                continue;
            }

            let namespaced = if namespace_prefix.is_empty() {
                name
            } else {
                format!("{}{}", namespace_prefix, name)
            };

            tools_array.push(json!({
                "type": "function",
                "function": {
                    "name": namespaced,
                    "description": t.description.as_deref().unwrap_or(""),
                    "parameters": t.input_schema
                }
            }));
            included_count += 1;
        }
        debug!("[MCP] å·²å¹¿å‘Šå‰ç«¯MCPå·¥å…· {} ä¸ª", included_count);

        debug!("[å·¥å…·] å·¥å…·åˆ—è¡¨æ„å»ºå®Œæˆï¼Œæ€»è®¡ {} ä¸ªå·¥å…·", tools_array.len());

        Value::Array(tools_array)
    }

    /// è·å– MCP å·¥å…·åˆ—è¡¨ï¼ˆä½¿ç”¨ LLMManager å†…éƒ¨å…±äº«ç¼“å­˜ï¼‰
    async fn get_frontend_mcp_tools_cached(
        &self,
        window: &Window,
        cache_ttl: Duration,
    ) -> Vec<FrontendMcpTool> {
        // ä¼˜å…ˆè¿”å›æœªè¿‡æœŸç¼“å­˜ï¼›è‹¥ç¼“å­˜ä¸ºç©ºåˆ™å°è¯•å¼ºåˆ¶åˆ·æ–°ä¸€æ¬¡ï¼Œé¿å…"ç©ºç¼“å­˜"å¯¼è‡´é•¿æœŸä¸å¹¿å‘Š
        if let Some(cache) = self.mcp_tool_cache.read().await.as_ref() {
            if !cache.is_expired() {
                if !cache.tools.is_empty() {
                    return cache.tools.clone();
                }
                // ç¼“å­˜æœªè¿‡æœŸä½†ä¸ºç©ºï¼šå°è¯•åˆ·æ–°ä¸€æ¬¡
            }
        }
        // é€šè¿‡æ¡¥æ¥è¯·æ±‚å·¥å…·
        let tools = match self
            .request_frontend_mcp_tools(window, Duration::from_millis(15_000))
            .await
        {
            Ok(v) => v,
            Err(e) => {
                warn!("MCP tools bridge failed: {}", e);
                vec![]
            }
        };
        let mut guard = self.mcp_tool_cache.write().await;
        *guard = Some(McpToolCache::new(tools.clone(), cache_ttl));
        tools
    }

    /// å…¬å¼€ï¼šé¢„çƒ­å‰ç«¯ MCP å·¥å…·æ¸…å•ç¼“å­˜ï¼ˆä¾›å‘½ä»¤è°ƒç”¨ï¼‰
    pub async fn preheat_mcp_tools_public(&self, window: &Window) -> usize {
        let ttl_ms: u64 = self
            .db
            .get_setting("mcp.performance.cache_ttl_ms")
            .ok()
            .flatten()
            .and_then(|v| v.parse::<u64>().ok())
            .unwrap_or(300_000);
        let tools = self
            .get_frontend_mcp_tools_cached(window, Duration::from_millis(ttl_ms))
            .await;
        tools.len()
    }

    async fn request_frontend_mcp_tools(
        &self,
        window: &Window,
        timeout: Duration,
    ) -> anyhow::Result<Vec<FrontendMcpTool>> {
        use tokio::sync::oneshot;
        use tokio::time::timeout as tokio_timeout;
        let correlation_id = uuid::Uuid::new_v4().to_string();
        let event_name = format!("mcp-bridge-tools-response:{}", correlation_id);
        let (tx, rx) = oneshot::channel::<serde_json::Value>();
        let w = window.clone();
        let tx_guard = std::sync::Arc::new(std::sync::Mutex::new(Some(tx)));
        let tx_guard_clone = tx_guard.clone();
        let id = w.listen(event_name.clone(), move |e| {
            // In Tauri v2, payload is provided as &str
            let payload_str = e.payload();
            if let Ok(val) = serde_json::from_str::<serde_json::Value>(payload_str) {
                if let Some(tx) = tx_guard_clone
                    .lock()
                    .unwrap_or_else(|e| e.into_inner())
                    .take()
                {
                    let _ = tx.send(val);
                }
            }
        });
        // å‘é€è¯·æ±‚
        window
            .emit(
                "mcp-bridge-tools-request",
                json!({"correlationId": correlation_id}),
            )
            .map_err(|e| anyhow::anyhow!("emit failed: {}", e))?;

        // ç­‰å¾…å“åº”
        let waited = tokio_timeout(timeout, rx).await;
        // æ¸…ç†ç›‘å¬å™¨ï¼ˆä¸è®ºæˆåŠŸå¤±è´¥ï¼‰
        let _ = window.unlisten(id);
        let val = match waited {
            Err(_) => return Err(anyhow::anyhow!("timeout waiting tools response")),
            Ok(Err(_)) => return Err(anyhow::anyhow!("bridge channel closed")),
            Ok(Ok(v)) => v,
        };
        let arr = val.get("tools").cloned().unwrap_or(json!([]));
        let tools: Vec<FrontendMcpTool> =
            serde_json::from_value(arr).unwrap_or_else(|_| Vec::new());
        Ok(tools)
    }

    /// æ¸…é™¤ MCP å·¥å…·ç¼“å­˜ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰
    pub async fn clear_mcp_tool_cache(&self) {
        let mut cache_guard = self.mcp_tool_cache.write().await;
        *cache_guard = None;
        info!("MCP tool cache cleared");
    }

    /// å°† MCP å·¥å…·è½¬æ¢ä¸º OpenAI å·¥å…· schema
    fn frontend_mcp_tool_to_openai_schema(mcp_tool: &FrontendMcpTool) -> Value {
        json!({
            "type": "function",
            "function": {
                "name": mcp_tool.name,
                "description": mcp_tool.description.as_deref().unwrap_or(""),
                "parameters": mcp_tool.input_schema
            }
        })
    }

    /// å°† OpenAI æ ¼å¼çš„å·¥å…·è°ƒç”¨è½¬æ¢ä¸ºå†…éƒ¨ ToolCall æ ¼å¼
    /// OpenAI æ ¼å¼: {"id": "call_123", "type": "function", "function": {"name": "tool_name", "arguments": "{...}"}}
    /// å†…éƒ¨æ ¼å¼: ToolCall { id, tool_name, args_json }
    fn convert_openai_tool_call(
        tool_call_value: &Value,
    ) -> std::result::Result<crate::models::ToolCall, String> {
        // å°è¯•ç›´æ¥è§£æä¸ºå†…éƒ¨æ ¼å¼ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
        if let Ok(tc) = serde_json::from_value::<crate::models::ToolCall>(tool_call_value.clone()) {
            return Ok(tc);
        }

        // OpenAI æ ¼å¼è§£æ
        let id = tool_call_value
            .get("id")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'id' field")?
            .to_string();

        let function = tool_call_value
            .get("function")
            .ok_or("Missing 'function' field")?;

        let tool_name = function
            .get("name")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'function.name' field")?
            .to_string();

        // ğŸ”§ ä¿®å¤ï¼šæŸäº› OpenAI å…¼å®¹ API çš„ arguments å·²æ˜¯ JSON å¯¹è±¡è€Œéå­—ç¬¦ä¸²
        let arguments_value = function
            .get("arguments")
            .ok_or("Missing 'function.arguments' field")?;

        // å¦‚æœ arguments å·²ç»æ˜¯ JSON å¯¹è±¡/æ•°ç»„ï¼Œç›´æ¥ä½¿ç”¨
        if !arguments_value.is_string() {
            if arguments_value.is_object() || arguments_value.is_array() {
                log::debug!(
                    "[llm_manager] convert_openai_tool_call: arguments å·²æ˜¯ JSON å€¼ (tool={})",
                    tool_name
                );
                return Ok(crate::models::ToolCall {
                    id,
                    tool_name,
                    args_json: arguments_value.clone(),
                });
            }
            // null æˆ–å…¶ä»–ç±»å‹ â†’ ç©ºå¯¹è±¡
            return Ok(crate::models::ToolCall {
                id,
                tool_name,
                args_json: Value::Object(serde_json::Map::new()),
            });
        }

        let arguments_str = arguments_value.as_str().unwrap_or("{}");

        // è§£æ arguments å­—ç¬¦ä¸²ä¸º JSON
        // å¦‚æœè§£æå¤±è´¥ï¼ˆå¸¸è§äº LLM è¾“å‡ºè¢« max_tokens æˆªæ–­ï¼‰ï¼Œå°è¯•ä¿®å¤æˆªæ–­çš„ JSON
        let args_json: Value = match serde_json::from_str(arguments_str) {
            Ok(v) => v,
            Err(e) => {
                // æ£€æµ‹æ˜¯å¦ä¸ºæˆªæ–­å¯¼è‡´çš„ EOF é”™è¯¯
                let err_msg = e.to_string();
                if err_msg.contains("EOF")
                    || err_msg.contains("unexpected end")
                    || err_msg.contains("trailing")
                {
                    log::warn!(
                        "[llm_manager] å·¥å…·è°ƒç”¨ JSON ç–‘ä¼¼è¢«æˆªæ–­ (len={}), å°è¯•ä¿®å¤...",
                        arguments_str.len()
                    );
                    match Self::try_repair_truncated_json(arguments_str) {
                        Some(repaired) => {
                            log::info!(
                                "[llm_manager] æˆªæ–­ JSON ä¿®å¤æˆåŠŸ: tool={}, original_len={}, repaired_len={}",
                                tool_name,
                                arguments_str.len(),
                                repaired.to_string().len()
                            );
                            repaired
                        }
                        None => {
                            return Err(format!(
                                "Failed to parse arguments JSON (truncated, repair failed): {}",
                                e
                            ));
                        }
                    }
                } else {
                    return Err(format!("Failed to parse arguments JSON: {}", e));
                }
            }
        };

        Ok(crate::models::ToolCall {
            id,
            tool_name,
            args_json,
        })
    }

    /// å°è¯•ä¿®å¤è¢«æˆªæ–­çš„å·¥å…·è°ƒç”¨ JSON
    ///
    /// LLM è¾“å‡ºè¢« max_tokens æˆªæ–­æ—¶ï¼ŒJSON å¯èƒ½åœ¨ä»»æ„ä½ç½®ä¸­æ–­ã€‚
    /// ç­–ç•¥ï¼šä»æˆªæ–­ä½ç½®å¼€å§‹å›é€€ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„é”®å€¼å¯¹ï¼Œç„¶åè¡¥å…¨ç¼ºå¤±çš„æ‹¬å·ã€‚
    ///
    /// æ”¯æŒä¿®å¤çš„åœºæ™¯ï¼š
    /// - å¯¹è±¡/æ•°ç»„æ²¡æœ‰é—­åˆï¼ˆç¼ºå°‘ `}` æˆ– `]`ï¼‰
    /// - å­—ç¬¦ä¸²å€¼è¢«æˆªæ–­ï¼ˆç¼ºå°‘ `"`ï¼‰
    /// - é”®å€¼å¯¹å†™äº†ä¸€åŠï¼ˆç¼ºå°‘ valueï¼‰
    fn try_repair_truncated_json(truncated: &str) -> Option<Value> {
        let s = truncated.trim();
        if s.is_empty() {
            return None;
        }

        // ç­–ç•¥ 1ï¼šç›´æ¥è¡¥å…¨æ‹¬å·
        // æ‰«æå·²æœ‰çš„ JSONï¼Œç»Ÿè®¡æœªé—­åˆçš„ { å’Œ [ ï¼Œåœ¨æœ«å°¾è¡¥ä¸Šå¯¹åº”çš„ } å’Œ ]
        if let Some(repaired) = Self::repair_by_bracket_completion(s) {
            return Some(repaired);
        }

        // ç­–ç•¥ 2ï¼šå›é€€åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„é€—å·/é”®å€¼å¯¹è¾¹ç•Œï¼Œå†è¡¥å…¨æ‹¬å·
        // ä»æœ«å°¾å‘å‰æ‰¾åˆ°æœ€åä¸€ä¸ª `,`ã€`}`ã€`]` æˆ–å®Œæ•´çš„ `"key": value` å¯¹
        if let Some(repaired) = Self::repair_by_truncation_rollback(s) {
            return Some(repaired);
        }

        log::warn!(
            "[llm_manager] æˆªæ–­ JSON ä¿®å¤å¤±è´¥ï¼Œæ‰€æœ‰ç­–ç•¥å‡æœªæˆåŠŸ (len={})",
            s.len()
        );
        None
    }

    /// ä¿®å¤ç­–ç•¥ 1ï¼šè¡¥å…¨ç¼ºå¤±çš„æ‹¬å·
    fn repair_by_bracket_completion(s: &str) -> Option<Value> {
        // æ‰«æå­—ç¬¦ä¸²ï¼Œè·Ÿè¸ªæ‹¬å·æ ˆï¼ˆå¿½ç•¥ JSON å­—ç¬¦ä¸²å†…éƒ¨çš„æ‹¬å·ï¼‰
        let mut stack: Vec<char> = Vec::new();
        let mut in_string = false;
        let mut escape_next = false;

        for ch in s.chars() {
            if escape_next {
                escape_next = false;
                continue;
            }
            if ch == '\\' && in_string {
                escape_next = true;
                continue;
            }
            if ch == '"' {
                in_string = !in_string;
                continue;
            }
            if in_string {
                continue;
            }
            match ch {
                '{' => stack.push('{'),
                '[' => stack.push('['),
                '}' => {
                    if stack.last() == Some(&'{') {
                        stack.pop();
                    }
                }
                ']' => {
                    if stack.last() == Some(&'[') {
                        stack.pop();
                    }
                }
                _ => {}
            }
        }

        if stack.is_empty() {
            // æ‹¬å·å·²å¹³è¡¡ï¼Œä½†å¯èƒ½æœ‰å…¶ä»–é—®é¢˜
            return serde_json::from_str(s).ok();
        }

        // å¦‚æœæˆªæ–­åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œå…ˆé—­åˆå­—ç¬¦ä¸²
        let mut repaired = s.to_string();
        if in_string {
            repaired.push('"');
        }

        // å¤„ç†æœ«å°¾å¯èƒ½çš„ä¸å®Œæ•´çŠ¶æ€ï¼š
        // å»æ‰æœ«å°¾çš„æ‚¬æŒ‚é€—å·ã€å†’å·ã€ä¸å®Œæ•´çš„ key
        let trimmed = repaired.trim_end();
        let last_char = trimmed.chars().last().unwrap_or(' ');
        if last_char == ',' || last_char == ':' {
            repaired = trimmed[..trimmed.len() - 1].to_string();
        }

        // è¡¥å…¨ç¼ºå¤±çš„æ‹¬å·ï¼ˆé€†åºé—­åˆï¼‰
        for &bracket in stack.iter().rev() {
            match bracket {
                '{' => repaired.push('}'),
                '[' => repaired.push(']'),
                _ => {}
            }
        }

        match serde_json::from_str::<Value>(&repaired) {
            Ok(v) => {
                log::debug!(
                    "[llm_manager] æˆªæ–­ JSON ä¿®å¤æˆåŠŸï¼ˆç­–ç•¥1ï¼šè¡¥å…¨æ‹¬å·ï¼‰, stack_depth={}",
                    stack.len()
                );
                Some(v)
            }
            Err(_) => None,
        }
    }

    /// ä¿®å¤ç­–ç•¥ 2ï¼šå›é€€åˆ°æœ€åä¸€ä¸ªå®Œæ•´è¾¹ç•Œåè¡¥å…¨
    fn repair_by_truncation_rollback(s: &str) -> Option<Value> {
        // ä»æœ«å°¾å¼€å§‹ï¼Œé€æ­¥æˆªæ–­ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªå¯ä»¥é€šè¿‡è¡¥å…¨æ‹¬å·ä¿®å¤çš„ä½ç½®
        // å°è¯•å‡ ä¸ªå¸¸è§çš„æˆªæ–­å›é€€ç‚¹
        let rollback_targets = [',', '}', ']', '\n'];

        for &target in &rollback_targets {
            if let Some(pos) = s.rfind(target) {
                let candidate = if target == ',' {
                    // åœ¨é€—å·å¤„æˆªæ–­ï¼šå»æ‰é€—å·åçš„éƒ¨åˆ†
                    &s[..pos]
                } else {
                    // åœ¨ } ] æ¢è¡Œå¤„æˆªæ–­ï¼šä¿ç•™åˆ°è¯¥å­—ç¬¦
                    &s[..=pos]
                };

                if let Some(repaired) = Self::repair_by_bracket_completion(candidate) {
                    log::debug!(
                        "[llm_manager] æˆªæ–­ JSON ä¿®å¤æˆåŠŸï¼ˆç­–ç•¥2ï¼šå›é€€åˆ° '{}' pos={}ï¼‰",
                        target,
                        pos
                    );
                    return Some(repaired);
                }
            }
        }

        None
    }

    fn coalesce_injection_texts(texts: &[String]) -> Option<String> {
        if texts.is_empty() {
            return None;
        }
        let per_item_max = 1600usize;
        let total_max = 20_000usize;
        let mut acc = String::new();
        for (idx, text) in texts.iter().enumerate() {
            let trimmed = text.trim();
            if trimmed.is_empty() {
                continue;
            }
            let mut chunk = trimmed.to_string();
            let original_len = chunk.chars().count();
            if original_len > per_item_max {
                chunk = chunk.chars().take(per_item_max).collect();
                debug!(
                    "  [{}] æ³¨å…¥æ®µè¶…é™ï¼Œæˆªæ–­ {} -> {} å­—ç¬¦",
                    idx,
                    original_len,
                    chunk.chars().count()
                );
            }
            if acc.chars().count() + chunk.chars().count() > total_max {
                debug!(
                    "  [{}] æ³¨å…¥æ€»é‡å·²è¾¾ä¸Šé™ï¼Œåœæ­¢ç»§ç»­è¿½åŠ ï¼ˆå½“å‰ {} å­—ç¬¦ï¼‰",
                    idx,
                    acc.chars().count()
                );
                break;
            }
            debug!(
                "  [{}] æ”¶å½•æ³¨å…¥æ®µï¼Œé•¿åº¦ {} å­—ç¬¦",
                idx,
                chunk.chars().count()
            );
            acc.push_str(&chunk);
        }
        if acc.is_empty() {
            None
        } else {
            debug!("[Inject] åˆå¹¶æ³¨å…¥æ–‡æœ¬æ€»é•¿åº¦: {} å­—ç¬¦", acc.chars().count());
            debug!(
                "[Inject] æ³¨å…¥é¢„è§ˆ: {}",
                &acc.chars().take(200).collect::<String>()
            );
            Some(acc)
        }
    }

    fn append_injection_to_system_message(messages: &mut Vec<Value>, inject_content: &str) {
        if inject_content.trim().is_empty() {
            warn!("[Inject] æ³¨å…¥å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡");
            return;
        }
        if let Some(first_msg) = messages.get_mut(0) {
            if first_msg["role"] == "system" {
                let current_content = first_msg["content"].as_str().unwrap_or("");
                first_msg["content"] =
                    json!(format!("{}\n\n{}", current_content, inject_content.trim()));
                debug!("[Inject] å·²å°†æ³¨å…¥æ–‡æœ¬è¿½åŠ åˆ°ç°æœ‰ç³»ç»Ÿæ¶ˆæ¯");
                return;
            }
        }
        messages.insert(
            0,
            json!({
                "role": "system",
                "content": inject_content.trim()
            }),
        );
        debug!("[Inject] æœªæ‰¾åˆ°ç³»ç»Ÿæ¶ˆæ¯ï¼Œå·²åˆ›å»ºæ–°çš„ç³»ç»Ÿæ¶ˆæ¯æ‰¿è½½æ³¨å…¥å†…å®¹");
    }

    /// æ„å»ºå›¾è°±æ£€ç´¢ç»“æœçš„æ³¨å…¥æ–‡æœ¬
    ///
    /// æ”¯æŒä¸¤ç§æ•°æ®æ ¼å¼ï¼š
    /// - æ—§æ ¼å¼ï¼ˆRagSourceInfoï¼‰ï¼š`file_name`, `chunk_text`
    /// - æ–°æ ¼å¼ï¼ˆSourceInfo from Chat V2ï¼‰ï¼š`title`, `snippet`
    fn build_prefetched_graph_injection(context: &HashMap<String, Value>) -> Option<String> {
        let prefetched = context
            .get("prefetched_graph_sources")
            .and_then(|v| v.as_array())?;
        if prefetched.is_empty() {
            return None;
        }
        let mut rows = Vec::new();
        for (idx, item) in prefetched.iter().enumerate() {
            // å…¼å®¹ä¸¤ç§å­—æ®µåæ ¼å¼ï¼šfile_name/title, chunk_text/snippet
            let title = item
                .get("file_name")
                .or_else(|| item.get("title"))
                .and_then(|v| v.as_str())
                .filter(|s| !s.trim().is_empty())
                .unwrap_or("Graph Insight");
            let snippet = item
                .get("chunk_text")
                .or_else(|| item.get("snippet"))
                .and_then(|v| v.as_str())
                .unwrap_or("");
            if snippet.trim().is_empty() {
                continue;
            }
            rows.push(format!("({}) {}\n{}", idx + 1, title, snippet));
            if rows.len() >= 5 {
                break;
            }
        }
        if rows.is_empty() {
            None
        } else {
            Some(format!("ã€ä¸ªäººå›¾è°±ã€‘\n{}\n\n", rows.join("\n\n")))
        }
    }

    /// P2-3: è°ƒç”¨ LLM è§£ææ–‡æ¡£å†…å®¹ä¸ºé¢˜ç›®
    pub async fn call_llm_for_question_parsing(&self, prompt: &str) -> Result<String> {
        // é»˜è®¤ä½¿ç”¨æ¨¡å‹äºŒé…ç½®ï¼ˆç¬¬ä¸€æ¨¡å‹å·²åºŸå¼ƒï¼‰
        let api_config = self.get_model2_config().await?;

        // è§£å¯† API Key
        let api_key = self.decrypt_api_key_if_needed(&api_config.api_key)?;

        // è·å–æ¨¡å‹ ID
        let model_id = api_config.model.clone();

        // æ„å»ºè¯·æ±‚
        let messages = vec![
            json!({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®è§£æåŠ©æ‰‹ã€‚è¯·å‡†ç¡®è¯†åˆ«æ–‡æ¡£ä¸­çš„é¢˜ç›®ï¼Œå¹¶æŒ‰æŒ‡å®šæ ¼å¼è¾“å‡ºã€‚"
            }),
            json!({
                "role": "user",
                "content": prompt
            }),
        ];

        let request_body = json!({
            "model": model_id,
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 4096
        });

        // å‘é€è¯·æ±‚
        let response = self
            .client
            .post(format!(
                "{}/chat/completions",
                api_config.base_url.trim_end_matches('/')
            ))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .map_err(|e| AppError::network(format!("LLM è¯·æ±‚å¤±è´¥: {}", e)))?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            return Err(AppError::network(format!(
                "LLM å“åº”é”™è¯¯ {}: {}",
                status, error_text
            )));
        }

        let response_json: Value = response
            .json()
            .await
            .map_err(|e| AppError::validation(format!("è§£æ LLM å“åº”å¤±è´¥: {}", e)))?;

        // æå–å“åº”å†…å®¹
        let content = response_json
            .get("choices")
            .and_then(|c| c.get(0))
            .and_then(|c| c.get("message"))
            .and_then(|m| m.get("content"))
            .and_then(|c| c.as_str())
            .ok_or_else(|| AppError::validation("LLM å“åº”æ ¼å¼é”™è¯¯"))?;

        Ok(content.to_string())
    }

    /// æµå¼è°ƒç”¨ LLM è§£æé¢˜ç›®ï¼Œæ¯è§£æå‡ºä¸€é“é¢˜ç›®ç«‹å³é€šè¿‡å›è°ƒè¿”å›
    /// callback è¿”å› false åˆ™ä¸­æ­¢æµ
    pub async fn call_llm_for_question_parsing_streaming<F>(
        &self,
        prompt: &str,
        model_config_id: Option<&str>,
        mut on_question: F,
    ) -> Result<Vec<Value>>
    where
        F: FnMut(Value) -> bool + Send,
    {
        let api_config = if let Some(config_id) = model_config_id {
            let configs = self.get_api_configs().await?;
            configs
                .into_iter()
                .find(|c| c.id == config_id)
                .ok_or_else(|| {
                    AppError::configuration(format!("æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¨¡å‹é…ç½®: {}", config_id))
                })?
        } else {
            self.get_model2_config().await?
        };

        let api_key = self.decrypt_api_key_if_needed(&api_config.api_key)?;
        let model_id = api_config.model.clone();

        let messages = vec![
            json!({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®è§£æåŠ©æ‰‹ã€‚è¯·å‡†ç¡®è¯†åˆ«æ–‡æ¡£ä¸­çš„é¢˜ç›®ï¼Œå¹¶æŒ‰æŒ‡å®šæ ¼å¼è¾“å‡ºã€‚"
            }),
            json!({
                "role": "user",
                "content": prompt
            }),
        ];

        let request_body = json!({
            "model": model_id,
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 8192,
            "stream": true
        });

        let response = self
            .client
            .post(format!(
                "{}/chat/completions",
                api_config.base_url.trim_end_matches('/')
            ))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .map_err(|e| AppError::network(format!("LLM æµå¼è¯·æ±‚å¤±è´¥: {}", e)))?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            return Err(AppError::network(format!(
                "LLM å“åº”é”™è¯¯ {}: {}",
                status, error_text
            )));
        }

        // æµå¼è§£æ
        let mut stream = response.bytes_stream();
        let mut sse_buffer = crate::utils::sse_buffer::SseLineBuffer::new();

        // æ ¹æ® provider_type é€‰æ‹©é€‚é…å™¨
        let provider = api_config.provider_type.as_deref().unwrap_or("openai");
        let adapter: Box<dyn crate::providers::ProviderAdapter> =
            match provider.to_lowercase().as_str() {
                "google" | "gemini" => Box::new(crate::providers::GeminiAdapter::new()),
                "anthropic" | "claude" => Box::new(crate::providers::AnthropicAdapter::new()),
                _ => Box::new(crate::providers::OpenAIAdapter),
            };

        let mut full_content = String::new();
        let mut all_questions: Vec<Value> = Vec::new();
        let mut json_parser = IncrementalJsonArrayParser::new();
        let mut stream_ended = false;
        let mut aborted = false;

        while !stream_ended && !aborted {
            let next_item = stream.next().await;
            let Some(next) = next_item else { break };

            let chunk = match next {
                Ok(b) => b,
                Err(e) => return Err(AppError::llm(format!("è¯»å–æµå¼å“åº”å¤±è´¥: {}", e))),
            };

            let text = String::from_utf8_lossy(&chunk);
            let lines = sse_buffer.process_chunk(&text);

            for line in lines {
                if crate::utils::sse_buffer::SseLineBuffer::check_done_marker(&line) {
                    stream_ended = true;
                    break;
                }
                let events = adapter.parse_stream(&line);
                for ev in events {
                    match ev {
                        crate::providers::StreamEvent::ContentChunk(s) => {
                            full_content.push_str(&s);
                            // å¢é‡è§£æ JSON æ•°ç»„
                            if let Some(questions) = json_parser.feed(&s) {
                                for q in questions {
                                    if !on_question(q.clone()) {
                                        aborted = true;
                                        break;
                                    }
                                    all_questions.push(q);
                                }
                            }
                        }
                        crate::providers::StreamEvent::Done => {
                            stream_ended = true;
                            break;
                        }
                        _ => {}
                    }
                    if aborted {
                        break;
                    }
                }
                if stream_ended || aborted {
                    break;
                }
            }
        }

        // å¤„ç†å‰©ä½™æœªè§£æçš„å†…å®¹
        if !aborted {
            if let Some(questions) = json_parser.finalize() {
                for q in questions {
                    if on_question(q.clone()) {
                        all_questions.push(q);
                    }
                }
            }
        }

        Ok(all_questions)
    }

    pub async fn call_llm_for_question_parsing_with_model(
        &self,
        prompt: &str,
        model_config_id: Option<&str>,
    ) -> Result<String> {
        let api_config = if let Some(config_id) = model_config_id {
            let configs = self.get_api_configs().await?;
            configs
                .into_iter()
                .find(|c| c.id == config_id)
                .ok_or_else(|| {
                    AppError::configuration(format!("æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¨¡å‹é…ç½®: {}", config_id))
                })?
        } else {
            self.get_model2_config().await?
        };

        let api_key = self.decrypt_api_key_if_needed(&api_config.api_key)?;
        let model_id = api_config.model.clone();

        let messages = vec![
            json!({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®è§£æåŠ©æ‰‹ã€‚è¯·å‡†ç¡®è¯†åˆ«æ–‡æ¡£ä¸­çš„é¢˜ç›®ï¼Œå¹¶æŒ‰æŒ‡å®šæ ¼å¼è¾“å‡ºã€‚"
            }),
            json!({
                "role": "user",
                "content": prompt
            }),
        ];

        let request_body = json!({
            "model": model_id,
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 4096
        });

        let response = self
            .client
            .post(format!(
                "{}/chat/completions",
                api_config.base_url.trim_end_matches('/')
            ))
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/json")
            .json(&request_body)
            .send()
            .await
            .map_err(|e| AppError::network(format!("LLM è¯·æ±‚å¤±è´¥: {}", e)))?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            return Err(AppError::network(format!(
                "LLM å“åº”é”™è¯¯ {}: {}",
                status, error_text
            )));
        }

        let response_json: Value = response
            .json()
            .await
            .map_err(|e| AppError::validation(format!("è§£æ LLM å“åº”å¤±è´¥: {}", e)))?;

        let content = response_json
            .get("choices")
            .and_then(|c| c.get(0))
            .and_then(|c| c.get("message"))
            .and_then(|m| m.get("content"))
            .and_then(|c| c.as_str())
            .ok_or_else(|| AppError::validation("LLM å“åº”æ ¼å¼é”™è¯¯"))?;

        Ok(content.to_string())
    }
}
